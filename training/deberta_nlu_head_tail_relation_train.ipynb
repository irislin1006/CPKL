{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iris/anaconda3/envs/cpkl/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset, DatasetDict, load_dataset\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from datasets import ClassLabel\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import nltk\n",
    "import evaluate\n",
    "import time\n",
    "\n",
    "\n",
    "# fix seeding for pytorch and huggingface\n",
    "import torch\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset config\n",
    "linking_data_path = \"./dimiss_items/data/model_gpt-3.5-turbo-0125\"\n",
    "TRAIN_DATA_PATH = f'{linking_data_path}/processed/gpt_label_full_train_df.json'\n",
    "VALID_DATA_PATH = f'{linking_data_path}/processed/gpt_label_full_valid_df.json'\n",
    "\n",
    "DS_TYPE = \"relation\" # \"full\" or \"head\" or \"tail\"\n",
    "USE_TAG = True\n",
    "\n",
    "LABEL_TO_ID = {\"entailment\": 0, \"not_entailment\": 1}\n",
    "ID_TO_LABEL = {0: \"entailment\", 1: \"not_entailment\"}\n",
    "\n",
    "COMFACT_LABEL_TO_ID = {True: 0, False: 1} # comFactDataLabelToId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def replace_phrases(sentence, person_a_tag):\n",
    "    sentence = sentence.lower()\n",
    "    # Pattern to find \"I am\" and replace with \"person a is\"\n",
    "    sentence = re.sub(r\"\\bi am\\b\", f\"{person_a_tag} is\", sentence, flags=re.IGNORECASE)\n",
    "    # Pattern to find \"I was\" and replace with \"person a was\"\n",
    "    sentence = re.sub(r\"\\bi was\\b\", f\"{person_a_tag} was\", sentence, flags=re.IGNORECASE)\n",
    "    sentence = re.sub(r\"\\bi\\b\", person_a_tag, sentence, flags=re.IGNORECASE)\n",
    "    sentence = re.sub(r\"\\bmy\\b\", f\"{person_a_tag}'s\", sentence, flags=re.IGNORECASE)\n",
    "    sentence = sentence.replace('person a', person_a_tag)\n",
    "    return sentence\n",
    "\n",
    "\n",
    "class DatasetLoader:\n",
    "    def __init__(self, train_data_path: str, valid_data_path: str, ds_type: str, sample_size: int = None):\n",
    "        self.train_data_path = train_data_path\n",
    "        self.valid_data_path = valid_data_path\n",
    "        self.sample_size = sample_size\n",
    "        self.pa_tag, self.pb_tag = 'Person A', 'Person B'\n",
    "        self.ds_type = ds_type\n",
    "\n",
    "    def get_conv_from_text(self, example):\n",
    "        center_utter = \"\"\n",
    "        post_utters, future_utters = [], []\n",
    "        for x in example['text']:\n",
    "            if x['type'] == 'ut':\n",
    "                center_utter = x['utter']\n",
    "            elif '-' in x['type']:\n",
    "                post_utters.append(x['utter'])\n",
    "            elif '+' in x['type']:\n",
    "                future_utters.append(x['utter'])\n",
    "\n",
    "        convs_list = '\\n'.join(post_utters + [center_utter] + future_utters)\n",
    "        return convs_list\n",
    "\n",
    "    def get_conv_with_tag_from_text(self, example):\n",
    "        def format_utter(utter, tag):\n",
    "            if utter.strip() == '':\n",
    "                return ''\n",
    "            return f\"{tag}: {utter}\"\n",
    "        center_utter = \"\"\n",
    "        post_utters, future_utters = [], []\n",
    "        for x in example['text']:\n",
    "            if x['type'] == 'ut':\n",
    "                center_utter = format_utter(x['utter'], self.pa_tag)\n",
    "            elif '-1' in x['type']:\n",
    "                post_utters.append(format_utter(x['utter'], self.pb_tag))\n",
    "            elif '-2' in x['type']:\n",
    "                post_utters.append(format_utter(x['utter'], self.pa_tag)) \n",
    "            elif '+1' in x['type']:\n",
    "                future_utters.append(format_utter(x['utter'], self.pb_tag)) \n",
    "            elif '+2' in x['type']:\n",
    "                future_utters.append(format_utter(x['utter'], self.pa_tag)) \n",
    "\n",
    "        convs_list = '\\n'.join(post_utters + [center_utter] + future_utters)\n",
    "        return convs_list #.lower()\n",
    "\n",
    "    def transform_df(self, df):\n",
    "        df['conv'] = df.apply(self.get_conv_from_text, axis=1) if not USE_TAG else df.apply(self.get_conv_with_tag_from_text, axis=1)\n",
    "        df['fact_text'] = df['fact_text'].apply(lambda x: x) if not USE_TAG else df['fact_text'].apply(lambda x: replace_phrases(x, self.pa_tag))\n",
    "        df['labels'] = df['gold_reference'].apply(lambda x: COMFACT_LABEL_TO_ID[x])\n",
    "        df['label_text'] = df['labels'].apply(lambda x: ID_TO_LABEL[x].lower())\n",
    "        return df\n",
    "\n",
    "    def create_pd_dataframe(self, data_path, sample_size=None):\n",
    "        df = pd.read_json(data_path)\n",
    "        # if self.ds_type == \"relation\":\n",
    "        #     df['peacok_relation'] = df['relation']\n",
    "        # if 'merged_head_tail' in data_path:\n",
    "        #     df = self.modify_merged_head_tail(df)\n",
    "        df = self.modify_merged_head_tail(df)\n",
    "        df = df.sample(sample_size) if sample_size else df\n",
    "        df = self.transform_df(df)\n",
    "        return df\n",
    "\n",
    "    def create_dataset(self, train_df, valid_df):\n",
    "        train_ds = Dataset.from_pandas(train_df)\n",
    "        valid_ds = Dataset.from_pandas(valid_df)\n",
    "\n",
    "        dataset = DatasetDict({\n",
    "            'train': train_ds,\n",
    "            'valid': valid_ds\n",
    "        })\n",
    "        return dataset\n",
    "    \n",
    "    # def get_relation(self, df):\n",
    "    #     return origonal_peacok_relation_df[origonal_peacok_relation_df['dialog_id'].isin(df['dialog_id'])]['peacok_relation']\n",
    "    \n",
    "    def modify_merged_head_tail(self, df):\n",
    "        if self.ds_type == \"head\":\n",
    "            df['gold_reference'] = df['gpt_tagged_head_gold_reference']\n",
    "            df['fact_text'] = df['gpt_tagged_head_fact_text']\n",
    "        elif self.ds_type == \"tail\":\n",
    "            df['gold_reference'] = df['gpt_tagged_tail_gold_reference']\n",
    "            df['fact_text'] = df['gpt_tagged_tail_fact_text']\n",
    "        elif self.ds_type == \"relation\":\n",
    "            # assert df['head_text'].equals(df['tail_text']), \"head and tail text should be the same\"\n",
    "            # df['text'] = df['tail_text']\n",
    "            df['gold_reference'] = df['gpt_tagged_head_gold_reference'] & df['gpt_tagged_tail_gold_reference']\n",
    "            df['fact_text'] = df.apply(lambda x: f\"{x['relation']} {x['gpt_tagged_head_fact_text']} and {x['gpt_tagged_tail_fact_text']}\", axis=1)\n",
    "            # df['fact_text'] = df.apply(lambda x: f\"{x['head_fact_text']} and {x['tail_fact_text']}; {x['peacok_relation']}\", axis=1)\n",
    "        else:\n",
    "            # assert df['head_text'].equals(df['tail_text']), \"head and tail text should be the same\"\n",
    "            # df['text'] = df['tail_text']\n",
    "            df['gold_reference'] = df['gpt_tagged_head_gold_reference'] & df['gpt_tagged_tail_gold_reference']\n",
    "            df['fact_text'] = df.apply(lambda x: f\"{x['gpt_tagged_head_fact_text']} and {x['gpt_tagged_tail_fact_text']}\", axis=1)\n",
    "        return df\n",
    "\n",
    "    def load(self):\n",
    "        train_df = self.create_pd_dataframe(self.train_data_path) # create_pd_dataframe(TRAIN_DATA_PATH, 5000)\n",
    "        valid_df = self.create_pd_dataframe(self.valid_data_path) # create_pd_dataframe(VALID_DATA_PATH, 500)\n",
    "        dataset = self.create_dataset(train_df, valid_df)\n",
    "        return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['dialog_id', 'relation', 'head', 'tail', 'text', 'gpt_tagged_head_old_label', 'gpt_tagged_head_gpt_output', 'gpt_tagged_head_fact_text', 'gpt_tagged_head_gold_reference', 'gpt_tagged_tail_gpt_output', 'gpt_tagged_tail_old_label', 'gpt_tagged_tail_action', 'gpt_tagged_tail_fact_text', 'gpt_tagged_tail_gold_reference', 'gold_reference', 'fact_text', 'conv', 'labels', 'label_text', '__index_level_0__'],\n",
       "        num_rows: 35821\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['dialog_id', 'relation', 'head', 'tail', 'text', 'gpt_tagged_head_old_label', 'gpt_tagged_head_gpt_output', 'gpt_tagged_head_fact_text', 'gpt_tagged_head_gold_reference', 'gpt_tagged_tail_gpt_output', 'gpt_tagged_tail_old_label', 'gpt_tagged_tail_action', 'gpt_tagged_tail_fact_text', 'gpt_tagged_tail_gold_reference', 'gold_reference', 'fact_text', 'conv', 'labels', 'label_text', '__index_level_0__'],\n",
       "        num_rows: 3981\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataset\n",
    "dataset_loader = DatasetLoader(TRAIN_DATA_PATH, VALID_DATA_PATH, DS_TYPE)\n",
    "dataset = dataset_loader.load()\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'additional_special_tokens': ['experience',\n",
       "  'experience_relationship',\n",
       "  'goal_plan_relationship',\n",
       "  'routine_habit_relationship',\n",
       "  'routine_habit',\n",
       "  'goal_plan',\n",
       "  'characteristic_relationship',\n",
       "  'characteristic']}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use train_ds and valid_ds to get all unique relations for specical tokenization\n",
    "relations_tokens = set(dataset['train']['relation'] + dataset['valid']['relation'])\n",
    "relations_special_tokens = {'additional_special_tokens': list(relations_tokens)}\n",
    "relations_special_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relation ds train len is 35821\n",
      "relation Positive: 7922(0.22115518829736747)\n",
      "relation Negative: 27899(0.7788448117026325)\n",
      "\n",
      "relation ds valid len is 3981\n",
      "relation Positive: 863(0.2167797035920623)\n",
      "relation Negative: 3118(0.7832202964079377)\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "counter = Counter([example['gold_reference'] for example in dataset['train']])\n",
    "valid_counter = Counter([example['gold_reference'] for example in dataset['valid']])\n",
    "\n",
    "print(f\"{DS_TYPE} ds train len is {len(dataset['train'])}\")\n",
    "print(f\"{DS_TYPE} Positive: {counter[True]}({counter[True]/len(dataset['train'])})\")\n",
    "print(f\"{DS_TYPE} Negative: {counter[False]}({counter[False]/len(dataset['train'])})\")\n",
    "print()\n",
    "print(f\"{DS_TYPE} ds valid len is {len(dataset['valid'])}\")\n",
    "print(f\"{DS_TYPE} Positive: {valid_counter[True]}({valid_counter[True]/len(dataset['valid'])})\")\n",
    "print(f\"{DS_TYPE} Negative: {valid_counter[False]}({valid_counter[False]/len(dataset['valid'])})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Person A: i don't have hair. i want to go to vegas. how are you? just to let you know i'm single.\n",
      "Person B: are you male or female? i can not wait to go back to school. do you use a wig? winter and fall is my favorite season\n",
      "Person A: i saw a wig on netflix. fall isn't that good. male, college? you do sleeping in? i do\n",
      "Person B: my sister loves me, and i love her. we are best friends. why not? does it get you down?\n",
      "Person A: it is just that in vegas fall causes weird people to come out. you saw right? i'm happy for you. love is so hard to come by. \n",
      "\n",
      "am always there for friends\n",
      "Person A is a loyal person\n",
      "None\n",
      "routine_habit_relationship\n",
      "routine_habit_relationship Person A is a loyal Person And am always there for friends\n"
     ]
    }
   ],
   "source": [
    "print(dataset['train'][0]['conv'], '\\n')\n",
    "print(dataset['train'][0]['gpt_tagged_tail_fact_text'])\n",
    "print(dataset['train'][0]['gpt_tagged_head_fact_text'])\n",
    "print(dataset['train'][0]['gpt_tagged_tail_action'])\n",
    "print(dataset['train'][0]['relation'])\n",
    "print(dataset['train'][0]['fact_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "- Model Name: microsoft/deberta-v3-large\n",
      "- Model Size: large\n",
      "- Ds Type: relation\n",
      "- Output Dir: ./dimiss_items/model/relation/deberta-v3-large-1720838176/\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mirislin1006\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/c/Users/iris/Desktop/wsl_shared/CPKL/wandb/run-20240712_213617-2v7iv4b6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/irislin1006/cpkl-relation-microsoft-deberta-v3-large/runs/2v7iv4b6' target=\"_blank\">deberta-v3-large-relation</a></strong> to <a href='https://wandb.ai/irislin1006/cpkl-relation-microsoft-deberta-v3-large' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/irislin1006/cpkl-relation-microsoft-deberta-v3-large' target=\"_blank\">https://wandb.ai/irislin1006/cpkl-relation-microsoft-deberta-v3-large</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/irislin1006/cpkl-relation-microsoft-deberta-v3-large/runs/2v7iv4b6' target=\"_blank\">https://wandb.ai/irislin1006/cpkl-relation-microsoft-deberta-v3-large/runs/2v7iv4b6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/irislin1006/cpkl-relation-microsoft-deberta-v3-large/runs/2v7iv4b6?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7efe22f3cfa0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load model config\n",
    "IS_TRAIN_SAMPLED = False\n",
    "MODEL_SIZE = \"large\"\n",
    "MODEL_NAME = f\"microsoft/deberta-v3-{MODEL_SIZE}\"\n",
    "# MODEL_NAME = f\"MoritzLaurer/deberta-v3-large-zeroshot-v1.1-all-33\"\n",
    "OUTPUT_DIR = f\"./dimiss_items/model/{DS_TYPE}/deberta-v3-{MODEL_SIZE}-{str(int(time.time()))}/\"\n",
    "\n",
    "print(f\"\"\"\n",
    "- Model Name: {MODEL_NAME}\n",
    "- Model Size: {MODEL_SIZE}\n",
    "- Ds Type: {DS_TYPE}\n",
    "- Output Dir: {OUTPUT_DIR}\n",
    "\"\"\")\n",
    "\n",
    "import wandb\n",
    "wandb.init(project=f\"cpkl-{DS_TYPE}-{MODEL_NAME.replace('/', '-')}\", name=f\"deberta-v3-{MODEL_SIZE}-{DS_TYPE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_and_tokenizer(model_name, label2id, id2label):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=False, model_max_length=512)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_name, label2id=label2id, id2label=id2label)\n",
    "    \n",
    "    if DS_TYPE == \"relation\":\n",
    "        tokenizer.add_special_tokens(relations_special_tokens)\n",
    "        model.resize_token_embeddings(len(tokenizer))\n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iris/anaconda3/envs/cpkl/lib/python3.9/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=False, model_max_length=512)\n",
    "# model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, label2id=label2id, id2label=id2label)\n",
    "model, tokenizer = load_model_and_tokenizer(MODEL_NAME, LABEL_TO_ID, ID_TO_LABEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Dataset for trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 35821/35821 [00:13<00:00, 2661.35 examples/s]\n",
      "Map: 100%|██████████| 3981/3981 [00:01<00:00, 2643.82 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using relation Dataset. Keys of tokenized dataset: ['labels', 'label_text', 'input_ids', 'token_type_ids', 'attention_mask']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def tokenize_function(examples):\n",
    "   return tokenizer(examples[\"conv\"], examples[\"fact_text\"], padding=True, truncation=True, max_length=512)\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize_function, batched=True, remove_columns=[\n",
    "   'dialog_id', \n",
    "   'text',\n",
    "   'relation',\n",
    "   'head',\n",
    "   'tail',\n",
    "   'gpt_tagged_head_old_label', \n",
    "   'gpt_tagged_head_gold_reference', \n",
    "   'gpt_tagged_head_fact_text', \n",
    "   'gpt_tagged_head_gpt_output', \n",
    "   'gpt_tagged_tail_old_label', \n",
    "   'gpt_tagged_tail_gold_reference', \n",
    "   'gpt_tagged_tail_fact_text', \n",
    "   'gpt_tagged_tail_gpt_output', \n",
    "   'gpt_tagged_tail_action', \n",
    "   'fact_text', \n",
    "   'gold_reference', \n",
    "   'conv',\n",
    "   '__index_level_0__'])\n",
    "print(f\"Using {DS_TYPE} Dataset. Keys of tokenized dataset: {list(tokenized_dataset['train'].features)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare trainer\n",
    "\n",
    "acc = evaluate.load(\"accuracy\")\n",
    "f1 = evaluate.load(\"f1\")\n",
    "precision = evaluate.load(\"precision\")\n",
    "recall = evaluate.load(\"recall\")\n",
    "roc_auc_score = evaluate.load(\"roc_auc\")\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    labels = eval_preds.label_ids\n",
    "    pred_logits = eval_preds.predictions\n",
    "    preds_max = np.argmax(pred_logits, axis=1)  # argmax on each row (axis=1) in the tensor\n",
    "    pred_probs = torch.softmax(torch.tensor(pred_logits), dim=1)[:, 0].numpy()\n",
    "      \n",
    "    print(\"Number of predictions: \", len(preds_max))\n",
    "    # compute f1, precision, recall, and accuracy \n",
    "    result = {}\n",
    "    result.update(acc.compute(predictions=preds_max, references=labels))\n",
    "    result.update(f1.compute(predictions=preds_max, references=labels, average='binary', pos_label=0))\n",
    "    result.update(precision.compute(predictions=preds_max, references=labels, average='binary', pos_label=0))\n",
    "    result.update(recall.compute(predictions=preds_max, references=labels, average='binary', pos_label=0))\n",
    "    result.update(roc_auc_score.compute(prediction_scores=pred_probs, references=1-labels))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trainer_args(output_dir):\n",
    "    if DS_TYPE == \"full\":\n",
    "        eval_steps=1500\n",
    "        save_steps=1500\n",
    "    elif DS_TYPE == \"head\":\n",
    "        eval_steps=1500\n",
    "        save_steps=1500\n",
    "    elif DS_TYPE == \"tail\":\n",
    "        # eval_steps=500\n",
    "        # save_steps=500\n",
    "        eval_steps=1500\n",
    "        save_steps=1500\n",
    "    elif DS_TYPE == \"relation\":\n",
    "        # eval_steps=500\n",
    "        # save_steps=500\n",
    "        eval_steps=1500\n",
    "        save_steps=1500\n",
    "    else:\n",
    "        raise ValueError(f\"'{DS_TYPE}' is invalid dataset type. Must be one of 'full', 'head', 'tail'\")\n",
    "    \n",
    "    return TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        per_device_train_batch_size=8,\n",
    "        per_device_eval_batch_size=8,\n",
    "        bf16 =False, # Overflows with bf16 \n",
    "        learning_rate=1e-6,\n",
    "        warmup_ratio=0.01,\n",
    "        weight_decay=0.01,\n",
    "        num_train_epochs=3,\n",
    "        # logging & evaluation strategies\n",
    "        logging_dir=f\"{output_dir}/logs\",\n",
    "        logging_strategy=\"steps\", \n",
    "        logging_steps=20,\n",
    "        evaluation_strategy=\"steps\",\n",
    "        eval_steps=eval_steps,\n",
    "        save_strategy=\"steps\",\n",
    "        save_steps=save_steps,\n",
    "        save_total_limit=5,\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"roc_auc\",\n",
    "        # push to hub parameters\n",
    "        report_to=\"wandb\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trainer(model, tokenized_dataset, output_dir):\n",
    "    training_args = get_trainer_args(output_dir)\n",
    "    trainer =Trainer(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_dataset[\"train\"],\n",
    "        eval_dataset=tokenized_dataset[\"valid\"],\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "    return trainer\n",
    "\n",
    "trainer = get_trainer(model, tokenized_dataset, OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13434' max='13434' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13434/13434 1:58:33, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Roc Auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.461000</td>\n",
       "      <td>0.404536</td>\n",
       "      <td>0.783220</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.840178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.375900</td>\n",
       "      <td>0.378919</td>\n",
       "      <td>0.853554</td>\n",
       "      <td>0.643861</td>\n",
       "      <td>0.680879</td>\n",
       "      <td>0.610660</td>\n",
       "      <td>0.885827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.406400</td>\n",
       "      <td>0.368532</td>\n",
       "      <td>0.835468</td>\n",
       "      <td>0.663585</td>\n",
       "      <td>0.595941</td>\n",
       "      <td>0.748552</td>\n",
       "      <td>0.891872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.364100</td>\n",
       "      <td>0.358631</td>\n",
       "      <td>0.850038</td>\n",
       "      <td>0.659829</td>\n",
       "      <td>0.649103</td>\n",
       "      <td>0.670915</td>\n",
       "      <td>0.896758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.330600</td>\n",
       "      <td>0.381238</td>\n",
       "      <td>0.849033</td>\n",
       "      <td>0.673192</td>\n",
       "      <td>0.634221</td>\n",
       "      <td>0.717265</td>\n",
       "      <td>0.899244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.443800</td>\n",
       "      <td>0.393020</td>\n",
       "      <td>0.845014</td>\n",
       "      <td>0.674750</td>\n",
       "      <td>0.618956</td>\n",
       "      <td>0.741599</td>\n",
       "      <td>0.899077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>0.367600</td>\n",
       "      <td>0.394927</td>\n",
       "      <td>0.850540</td>\n",
       "      <td>0.661355</td>\n",
       "      <td>0.649888</td>\n",
       "      <td>0.673233</td>\n",
       "      <td>0.900168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.270200</td>\n",
       "      <td>0.411072</td>\n",
       "      <td>0.850289</td>\n",
       "      <td>0.672887</td>\n",
       "      <td>0.639208</td>\n",
       "      <td>0.710313</td>\n",
       "      <td>0.899543</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of predictions:  3981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iris/anaconda3/envs/cpkl/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of predictions:  3981\n",
      "Number of predictions:  3981\n",
      "Number of predictions:  3981\n",
      "Number of predictions:  3981\n",
      "Number of predictions:  3981\n",
      "Number of predictions:  3981\n",
      "Number of predictions:  3981\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=13434, training_loss=0.38004996415598685, metrics={'train_runtime': 7114.3469, 'train_samples_per_second': 15.105, 'train_steps_per_second': 1.888, 'total_flos': 5.22508046957067e+16, 'train_loss': 0.38004996415598685, 'epoch': 3.0})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of predictions:  3981\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot a roc curve with sk learn  and matplot lib\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_roc_curve(trainer, tokenized_dataset):\n",
    "    output = trainer.predict(tokenized_dataset[\"valid\"])\n",
    "    labels = 1 - output.label_ids\n",
    "    pred_logits = output.predictions\n",
    "    pred_probs = torch.softmax(torch.tensor(pred_logits), dim=1)[:, 0].numpy()\n",
    "    fpr, tpr, thresholds = roc_curve(labels, pred_probs, pos_label=1)\n",
    "    plt.plot(fpr, tpr, label=f\"ROC curve (area = {auc(fpr, tpr):.2f})\")\n",
    "    return pred_probs, thresholds\n",
    "\n",
    "pred_probs, thres = plot_roc_curve(trainer, tokenized_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.2\n",
      "{'accuracy': 0.8467721677970359, 'f1': 0.6802935010482181, 'precision': 0.6210526315789474, 'recall': 0.7520278099652375, 'roc_auc': 0.9001684979452467}\n",
      "Threshold: 0.3\n",
      "{'accuracy': 0.8512936448128611, 'f1': 0.6775599128540304, 'precision': 0.6392600205549845, 'recall': 0.7207415990730012, 'roc_auc': 0.9001684979452467}\n",
      "Threshold: 0.4\n",
      "{'accuracy': 0.8507912584777694, 'f1': 0.67, 'precision': 0.6435432230522946, 'recall': 0.6987253765932793, 'roc_auc': 0.9001684979452467}\n",
      "Threshold: 0.5\n",
      "{'accuracy': 0.8505400653102235, 'f1': 0.6613545816733067, 'precision': 0.6498881431767338, 'recall': 0.6732329084588644, 'roc_auc': 0.9001684979452467}\n",
      "Threshold: 0.6\n",
      "{'accuracy': 0.853051996985682, 'f1': 0.6596858638743456, 'precision': 0.6623831775700935, 'recall': 0.657010428736964, 'roc_auc': 0.9001684979452467}\n",
      "Threshold: 0.7\n",
      "{'accuracy': 0.8548103491585028, 'f1': 0.6579881656804735, 'precision': 0.6723095525997581, 'recall': 0.6442641946697567, 'roc_auc': 0.9001684979452467}\n"
     ]
    }
   ],
   "source": [
    "# compute f1, precision, recall, and accuracy by given threshold\n",
    "def compute_metrics_with_threshold(pred_probs, thres, labels):\n",
    "    preds = (pred_probs > thres).astype(int)\n",
    "    result = {}\n",
    "    result.update(acc.compute(predictions=preds, references=labels))\n",
    "    result.update(f1.compute(predictions=preds, references=labels, average='binary', pos_label=1))\n",
    "    result.update(precision.compute(predictions=preds, references=labels, average='binary', pos_label=1))\n",
    "    result.update(recall.compute(predictions=preds, references=labels, average='binary', pos_label=1))\n",
    "    result.update(roc_auc_score.compute(prediction_scores=pred_probs, references=labels))\n",
    "    return result\n",
    "\n",
    "for t in [0.2, 0.3, 0.4, 0.5, 0.6, 0.7]:\n",
    "    print(f\"Threshold: {t}\")\n",
    "    print(compute_metrics_with_threshold(pred_probs, t, 1 - np.array(tokenized_dataset[\"valid\"][\"labels\"]).astype(int)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./dimiss_items/model/relation/deberta-v3-large-1720838176/'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OUTPUT_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, tokenizer, output_dir):\n",
    "    model.save_pretrained(output_dir)\n",
    "    tokenizer.save_pretrained(output_dir)\n",
    "# OUTPUT_DIR = 'agents/dimiss_items/model/full/deberta-v3-large-1710086328/'\n",
    "save_model_path = OUTPUT_DIR + f\"deberta_v3_large_sample_{IS_TRAIN_SAMPLED}\"\n",
    "save_model(model, tokenizer, save_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cpkl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
