{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iris/anaconda3/envs/cpkl/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset, DatasetDict, load_dataset\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from datasets import ClassLabel\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import nltk\n",
    "import evaluate\n",
    "import time\n",
    "\n",
    "\n",
    "# fix seeding for pytorch and huggingface\n",
    "import torch\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deberta NLU Full Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset config\n",
    "linking_data_path = \"./dimiss_items/data/model_gpt-3.5-turbo-0125\"\n",
    "TRAIN_DATA_PATH = f'{linking_data_path}/processed/gpt_label_full_train_df.json'\n",
    "VALID_DATA_PATH = f'{linking_data_path}/processed/gpt_label_full_valid_df.json'\n",
    "\n",
    "DS_TYPE = \"full\"\n",
    "USE_TAG = True\n",
    "\n",
    "LABEL_TO_ID = {\"entailment\": 0, \"not_entailment\": 1}\n",
    "ID_TO_LABEL = {0: \"entailment\", 1: \"not_entailment\"}\n",
    "\n",
    "COMFACT_LABEL_TO_ID = {True: 0, False: 1} # comFactDataLabelToId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def replace_phrases(sentence, person_a_tag):\n",
    "    sentence = sentence.lower()\n",
    "    # Pattern to find \"I am\" and replace with \"person a is\"\n",
    "    sentence = re.sub(r\"\\bi am\\b\", f\"{person_a_tag} is\", sentence, flags=re.IGNORECASE)\n",
    "    # Pattern to find \"I was\" and replace with \"person a was\"\n",
    "    sentence = re.sub(r\"\\bi was\\b\", f\"{person_a_tag} was\", sentence, flags=re.IGNORECASE)\n",
    "    sentence = re.sub(r\"\\bi\\b\", person_a_tag, sentence, flags=re.IGNORECASE)\n",
    "    sentence = re.sub(r\"\\bmy\\b\", f\"{person_a_tag}'s\", sentence, flags=re.IGNORECASE)\n",
    "    sentence = sentence.replace('person a', person_a_tag)\n",
    "    return sentence\n",
    "\n",
    "\n",
    "class DatasetLoader:\n",
    "    def __init__(self, train_data_path: str, valid_data_path: str, ds_type: str, sample_size: int = None):\n",
    "        self.train_data_path = train_data_path\n",
    "        self.valid_data_path = valid_data_path\n",
    "        self.sample_size = sample_size\n",
    "        self.pa_tag, self.pb_tag = 'Person A', 'Person B'\n",
    "        self.ds_type = ds_type\n",
    "\n",
    "    def get_conv_from_text(self, example):\n",
    "        center_utter = \"\"\n",
    "        post_utters, future_utters = [], []\n",
    "        for x in example['text']:\n",
    "            if x['type'] == 'ut':\n",
    "                center_utter = x['utter']\n",
    "            elif '-' in x['type']:\n",
    "                post_utters.append(x['utter'])\n",
    "            elif '+' in x['type']:\n",
    "                future_utters.append(x['utter'])\n",
    "\n",
    "        convs_list = '\\n'.join(post_utters + [center_utter] + future_utters)\n",
    "        return convs_list\n",
    "\n",
    "    def get_conv_with_tag_from_text(self, example):\n",
    "        def format_utter(utter, tag):\n",
    "            if utter.strip() == '':\n",
    "                return ''\n",
    "            return f\"{tag}: {utter}\"\n",
    "        center_utter = \"\"\n",
    "        post_utters, future_utters = [], []\n",
    "        for x in example['text']:\n",
    "            if x['type'] == 'ut':\n",
    "                center_utter = format_utter(x['utter'], self.pa_tag)\n",
    "            elif '-1' in x['type']:\n",
    "                post_utters.append(format_utter(x['utter'], self.pb_tag))\n",
    "            elif '-2' in x['type']:\n",
    "                post_utters.append(format_utter(x['utter'], self.pa_tag)) \n",
    "            elif '+1' in x['type']:\n",
    "                future_utters.append(format_utter(x['utter'], self.pb_tag)) \n",
    "            elif '+2' in x['type']:\n",
    "                future_utters.append(format_utter(x['utter'], self.pa_tag)) \n",
    "\n",
    "        convs_list = '\\n'.join(post_utters + [center_utter] + future_utters)\n",
    "        return convs_list #.lower()\n",
    "\n",
    "    def transform_df(self, df):\n",
    "        df['conv'] = df.apply(self.get_conv_from_text, axis=1) if not USE_TAG else df.apply(self.get_conv_with_tag_from_text, axis=1)\n",
    "        df['fact_text'] = df['fact_text'].apply(lambda x: x) if not USE_TAG else df['fact_text'].apply(lambda x: replace_phrases(x, self.pa_tag))\n",
    "        df['labels'] = df['gold_reference'].apply(lambda x: COMFACT_LABEL_TO_ID[x])\n",
    "        df['label_text'] = df['labels'].apply(lambda x: ID_TO_LABEL[x].lower())\n",
    "        return df\n",
    "\n",
    "    def create_pd_dataframe(self, data_path, sample_size=None):\n",
    "        df = pd.read_json(data_path)\n",
    "        # if self.ds_type == \"relation\":\n",
    "        #     df['peacok_relation'] = df['relation']\n",
    "        # if 'merged_head_tail' in data_path:\n",
    "        #     df = self.modify_merged_head_tail(df)\n",
    "        df = self.modify_merged_head_tail(df)\n",
    "        df = df.sample(sample_size) if sample_size else df\n",
    "        df = self.transform_df(df)\n",
    "        return df\n",
    "\n",
    "    def create_dataset(self, train_df, valid_df):\n",
    "        train_ds = Dataset.from_pandas(train_df)\n",
    "        valid_ds = Dataset.from_pandas(valid_df)\n",
    "\n",
    "        dataset = DatasetDict({\n",
    "            'train': train_ds,\n",
    "            'valid': valid_ds\n",
    "        })\n",
    "        return dataset\n",
    "    \n",
    "    # def get_relation(self, df):\n",
    "    #     return origonal_peacok_relation_df[origonal_peacok_relation_df['dialog_id'].isin(df['dialog_id'])]['peacok_relation']\n",
    "    \n",
    "    def modify_merged_head_tail(self, df):\n",
    "        if self.ds_type == \"head\":\n",
    "            df['gold_reference'] = df['gpt_tagged_head_gold_reference']\n",
    "            df['fact_text'] = df['gpt_tagged_head_fact_text']\n",
    "        elif self.ds_type == \"tail\":\n",
    "            df['gold_reference'] = df['gpt_tagged_tail_gold_reference']\n",
    "            df['fact_text'] = df['gpt_tagged_tail_fact_text']\n",
    "        elif self.ds_type == \"relation\":\n",
    "            # assert df['head_text'].equals(df['tail_text']), \"head and tail text should be the same\"\n",
    "            # df['text'] = df['tail_text']\n",
    "            df['gold_reference'] = df['gpt_tagged_head_gold_reference'] & df['gpt_tagged_tail_gold_reference']\n",
    "            df['fact_text'] = df.apply(lambda x: f\"{x['relation']} {x['gpt_tagged_head_fact_text']} and {x['gpt_tagged_tail_fact_text']}\", axis=1)\n",
    "            # df['fact_text'] = df.apply(lambda x: f\"{x['head_fact_text']} and {x['tail_fact_text']}; {x['peacok_relation']}\", axis=1)\n",
    "        else:\n",
    "            # assert df['head_text'].equals(df['tail_text']), \"head and tail text should be the same\"\n",
    "            # df['text'] = df['tail_text']\n",
    "            df['gold_reference'] = df['gpt_tagged_head_gold_reference'] & df['gpt_tagged_tail_gold_reference']\n",
    "            df['fact_text'] = df.apply(lambda x: f\"{x['gpt_tagged_head_fact_text']} and {x['gpt_tagged_tail_fact_text']}\", axis=1)\n",
    "        return df\n",
    "\n",
    "    def load(self):\n",
    "        train_df = self.create_pd_dataframe(self.train_data_path) # create_pd_dataframe(TRAIN_DATA_PATH, 5000)\n",
    "        valid_df = self.create_pd_dataframe(self.valid_data_path) # create_pd_dataframe(VALID_DATA_PATH, 500)\n",
    "        dataset = self.create_dataset(train_df, valid_df)\n",
    "        return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['dialog_id', 'relation', 'head', 'tail', 'text', 'gpt_tagged_head_old_label', 'gpt_tagged_head_gpt_output', 'gpt_tagged_head_fact_text', 'gpt_tagged_head_gold_reference', 'gpt_tagged_tail_gpt_output', 'gpt_tagged_tail_old_label', 'gpt_tagged_tail_action', 'gpt_tagged_tail_fact_text', 'gpt_tagged_tail_gold_reference', 'gold_reference', 'fact_text', 'conv', 'labels', 'label_text', '__index_level_0__'],\n",
       "        num_rows: 35821\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['dialog_id', 'relation', 'head', 'tail', 'text', 'gpt_tagged_head_old_label', 'gpt_tagged_head_gpt_output', 'gpt_tagged_head_fact_text', 'gpt_tagged_head_gold_reference', 'gpt_tagged_tail_gpt_output', 'gpt_tagged_tail_old_label', 'gpt_tagged_tail_action', 'gpt_tagged_tail_fact_text', 'gpt_tagged_tail_gold_reference', 'gold_reference', 'fact_text', 'conv', 'labels', 'label_text', '__index_level_0__'],\n",
       "        num_rows: 3981\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataset\n",
    "dataset_loader = DatasetLoader(TRAIN_DATA_PATH, VALID_DATA_PATH, DS_TYPE)\n",
    "dataset = dataset_loader.load()\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'additional_special_tokens': ['routine_habit_relationship',\n",
       "  'experience',\n",
       "  'characteristic',\n",
       "  'goal_plan',\n",
       "  'characteristic_relationship',\n",
       "  'routine_habit',\n",
       "  'experience_relationship',\n",
       "  'goal_plan_relationship']}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use train_ds and valid_ds to get all unique relations for specical tokenization\n",
    "relations_tokens = set(dataset['train']['relation'] + dataset['valid']['relation'])\n",
    "relations_special_tokens = {'additional_special_tokens': list(relations_tokens)}\n",
    "relations_special_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full ds train len is 35821\n",
      "full Positive: 7922(0.22115518829736747)\n",
      "full Negative: 27899(0.7788448117026325)\n",
      "\n",
      "full ds valid len is 3981\n",
      "full Positive: 863(0.2167797035920623)\n",
      "full Negative: 3118(0.7832202964079377)\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "counter = Counter([example['gold_reference'] for example in dataset['train']])\n",
    "valid_counter = Counter([example['gold_reference'] for example in dataset['valid']])\n",
    "\n",
    "print(f\"{DS_TYPE} ds train len is {len(dataset['train'])}\")\n",
    "print(f\"{DS_TYPE} Positive: {counter[True]}({counter[True]/len(dataset['train'])})\")\n",
    "print(f\"{DS_TYPE} Negative: {counter[False]}({counter[False]/len(dataset['train'])})\")\n",
    "print()\n",
    "print(f\"{DS_TYPE} ds valid len is {len(dataset['valid'])}\")\n",
    "print(f\"{DS_TYPE} Positive: {valid_counter[True]}({valid_counter[True]/len(dataset['valid'])})\")\n",
    "print(f\"{DS_TYPE} Negative: {valid_counter[False]}({valid_counter[False]/len(dataset['valid'])})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Person A: i don't have hair. i want to go to vegas. how are you? just to let you know i'm single.\n",
      "Person B: are you male or female? i can not wait to go back to school. do you use a wig? winter and fall is my favorite season\n",
      "Person A: i saw a wig on netflix. fall isn't that good. male, college? you do sleeping in? i do\n",
      "Person B: my sister loves me, and i love her. we are best friends. why not? does it get you down?\n",
      "Person A: it is just that in vegas fall causes weird people to come out. you saw right? i'm happy for you. love is so hard to come by. \n",
      "\n",
      "am always there for friends\n",
      "Person A is a loyal person\n",
      "None\n",
      "routine_habit_relationship\n",
      "Person A is a loyal Person And am always there for friends\n"
     ]
    }
   ],
   "source": [
    "print(dataset['train'][0]['conv'], '\\n')\n",
    "print(dataset['train'][0]['gpt_tagged_tail_fact_text'])\n",
    "print(dataset['train'][0]['gpt_tagged_head_fact_text'])\n",
    "print(dataset['train'][0]['gpt_tagged_tail_action'])\n",
    "print(dataset['train'][0]['relation'])\n",
    "print(dataset['train'][0]['fact_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "- Model Name: microsoft/deberta-v3-large\n",
      "- Model Size: large\n",
      "- Ds Type: full\n",
      "- Output Dir: ./dimiss_items/model/full/deberta-v3-large-1720902951/\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mirislin1006\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/c/Users/iris/Desktop/wsl_shared/CPKL/wandb/run-20240713_153552-2dvyjni0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/irislin1006/cpkl-full-microsoft-deberta-v3-large/runs/2dvyjni0' target=\"_blank\">deberta-v3-large-full</a></strong> to <a href='https://wandb.ai/irislin1006/cpkl-full-microsoft-deberta-v3-large' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/irislin1006/cpkl-full-microsoft-deberta-v3-large' target=\"_blank\">https://wandb.ai/irislin1006/cpkl-full-microsoft-deberta-v3-large</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/irislin1006/cpkl-full-microsoft-deberta-v3-large/runs/2dvyjni0' target=\"_blank\">https://wandb.ai/irislin1006/cpkl-full-microsoft-deberta-v3-large/runs/2dvyjni0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/irislin1006/cpkl-full-microsoft-deberta-v3-large/runs/2dvyjni0?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7fa7a9fdc370>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load model config\n",
    "IS_TRAIN_SAMPLED = False\n",
    "MODEL_SIZE = \"large\"\n",
    "MODEL_NAME = f\"microsoft/deberta-v3-{MODEL_SIZE}\"\n",
    "# MODEL_NAME = f\"MoritzLaurer/deberta-v3-large-zeroshot-v1.1-all-33\"\n",
    "OUTPUT_DIR = f\"./dimiss_items/model/{DS_TYPE}/deberta-v3-{MODEL_SIZE}-{str(int(time.time()))}/\"\n",
    "\n",
    "print(f\"\"\"\n",
    "- Model Name: {MODEL_NAME}\n",
    "- Model Size: {MODEL_SIZE}\n",
    "- Ds Type: {DS_TYPE}\n",
    "- Output Dir: {OUTPUT_DIR}\n",
    "\"\"\")\n",
    "\n",
    "import wandb\n",
    "wandb.init(project=f\"cpkl-{DS_TYPE}-{MODEL_NAME.replace('/', '-')}\", name=f\"deberta-v3-{MODEL_SIZE}-{DS_TYPE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_and_tokenizer(model_name, label2id, id2label):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=False, model_max_length=512)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_name, label2id=label2id, id2label=id2label)\n",
    "    \n",
    "    if DS_TYPE == \"relation\":\n",
    "        tokenizer.add_special_tokens(relations_special_tokens)\n",
    "        model.resize_token_embeddings(len(tokenizer))\n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iris/anaconda3/envs/cpkl/lib/python3.9/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=False, model_max_length=512)\n",
    "# model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, label2id=label2id, id2label=id2label)\n",
    "model, tokenizer = load_model_and_tokenizer(MODEL_NAME, LABEL_TO_ID, ID_TO_LABEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Dataset for trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 35821/35821 [00:12<00:00, 2873.42 examples/s]\n",
      "Map: 100%|██████████| 3981/3981 [00:01<00:00, 2728.95 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using full Dataset. Keys of tokenized dataset: ['labels', 'label_text', 'input_ids', 'token_type_ids', 'attention_mask']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def tokenize_function(examples):\n",
    "   return tokenizer(examples[\"conv\"], examples[\"fact_text\"], padding=True, truncation=True, max_length=512)\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize_function, batched=True, remove_columns=[\n",
    "   'dialog_id', \n",
    "   'text',\n",
    "   'relation',\n",
    "   'head',\n",
    "   'tail',\n",
    "   'gpt_tagged_head_old_label', \n",
    "   'gpt_tagged_head_gold_reference', \n",
    "   'gpt_tagged_head_fact_text', \n",
    "   'gpt_tagged_head_gpt_output', \n",
    "   'gpt_tagged_tail_old_label', \n",
    "   'gpt_tagged_tail_gold_reference', \n",
    "   'gpt_tagged_tail_fact_text', \n",
    "   'gpt_tagged_tail_gpt_output', \n",
    "   'gpt_tagged_tail_action', \n",
    "   'fact_text', \n",
    "   'gold_reference', \n",
    "   'conv',\n",
    "   '__index_level_0__'])\n",
    "print(f\"Using {DS_TYPE} Dataset. Keys of tokenized dataset: {list(tokenized_dataset['train'].features)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare trainer\n",
    "\n",
    "acc = evaluate.load(\"accuracy\")\n",
    "f1 = evaluate.load(\"f1\")\n",
    "precision = evaluate.load(\"precision\")\n",
    "recall = evaluate.load(\"recall\")\n",
    "roc_auc_score = evaluate.load(\"roc_auc\")\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    labels = eval_preds.label_ids\n",
    "    pred_logits = eval_preds.predictions\n",
    "    preds_max = np.argmax(pred_logits, axis=1)  # argmax on each row (axis=1) in the tensor\n",
    "    pred_probs = torch.softmax(torch.tensor(pred_logits), dim=1)[:, 0].numpy()\n",
    "      \n",
    "    print(\"Number of predictions: \", len(preds_max))\n",
    "    # compute f1, precision, recall, and accuracy \n",
    "    result = {}\n",
    "    result.update(acc.compute(predictions=preds_max, references=labels))\n",
    "    result.update(f1.compute(predictions=preds_max, references=labels, average='binary', pos_label=0))\n",
    "    result.update(precision.compute(predictions=preds_max, references=labels, average='binary', pos_label=0))\n",
    "    result.update(recall.compute(predictions=preds_max, references=labels, average='binary', pos_label=0))\n",
    "    result.update(roc_auc_score.compute(prediction_scores=pred_probs, references=1-labels))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trainer_args(output_dir):\n",
    "    if DS_TYPE == \"full\":\n",
    "        eval_steps=1500\n",
    "        save_steps=1500\n",
    "    elif DS_TYPE == \"head\":\n",
    "        eval_steps=3000\n",
    "        save_steps=3000\n",
    "    elif DS_TYPE == \"tail\":\n",
    "        eval_steps=3000\n",
    "        save_steps=3000\n",
    "    elif DS_TYPE == \"relation\":\n",
    "        # eval_steps=500\n",
    "        # save_steps=500\n",
    "        eval_steps=1500\n",
    "        save_steps=1500\n",
    "    else:\n",
    "        raise ValueError(f\"'{DS_TYPE}' is invalid dataset type. Must be one of 'full', 'head', 'tail'\")\n",
    "    \n",
    "    return TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        per_device_train_batch_size=8,\n",
    "        per_device_eval_batch_size=8,\n",
    "        bf16 =False, # Overflows with bf16 \n",
    "        learning_rate=1e-6,\n",
    "        warmup_ratio=0.01,\n",
    "        weight_decay=0.01,\n",
    "        num_train_epochs=3,\n",
    "        # logging & evaluation strategies\n",
    "        logging_dir=f\"{output_dir}/logs\",\n",
    "        logging_strategy=\"steps\", \n",
    "        logging_steps=20,\n",
    "        evaluation_strategy=\"steps\",\n",
    "        eval_steps=eval_steps,\n",
    "        save_strategy=\"steps\",\n",
    "        save_steps=save_steps,\n",
    "        save_total_limit=5,\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"roc_auc\",\n",
    "        # push to hub parameters\n",
    "        report_to=\"wandb\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trainer(model, tokenized_dataset, output_dir):\n",
    "    training_args = get_trainer_args(output_dir)\n",
    "    trainer =Trainer(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_dataset[\"train\"],\n",
    "        eval_dataset=tokenized_dataset[\"valid\"],\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "    return trainer\n",
    "\n",
    "trainer = get_trainer(model, tokenized_dataset, OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13434' max='13434' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13434/13434 1:55:40, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Roc Auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.384500</td>\n",
       "      <td>0.379521</td>\n",
       "      <td>0.829942</td>\n",
       "      <td>0.594368</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.574739</td>\n",
       "      <td>0.839851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.364400</td>\n",
       "      <td>0.392636</td>\n",
       "      <td>0.849284</td>\n",
       "      <td>0.644550</td>\n",
       "      <td>0.659394</td>\n",
       "      <td>0.630359</td>\n",
       "      <td>0.879558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.383600</td>\n",
       "      <td>0.385900</td>\n",
       "      <td>0.823160</td>\n",
       "      <td>0.661213</td>\n",
       "      <td>0.565432</td>\n",
       "      <td>0.796060</td>\n",
       "      <td>0.891049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.308900</td>\n",
       "      <td>0.350454</td>\n",
       "      <td>0.854810</td>\n",
       "      <td>0.662383</td>\n",
       "      <td>0.667845</td>\n",
       "      <td>0.657010</td>\n",
       "      <td>0.896535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.323600</td>\n",
       "      <td>0.370420</td>\n",
       "      <td>0.848279</td>\n",
       "      <td>0.673866</td>\n",
       "      <td>0.630940</td>\n",
       "      <td>0.723059</td>\n",
       "      <td>0.899742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.425100</td>\n",
       "      <td>0.386053</td>\n",
       "      <td>0.840744</td>\n",
       "      <td>0.671162</td>\n",
       "      <td>0.607512</td>\n",
       "      <td>0.749710</td>\n",
       "      <td>0.899817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>0.400400</td>\n",
       "      <td>0.378238</td>\n",
       "      <td>0.857322</td>\n",
       "      <td>0.671676</td>\n",
       "      <td>0.670127</td>\n",
       "      <td>0.673233</td>\n",
       "      <td>0.902889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.284800</td>\n",
       "      <td>0.398616</td>\n",
       "      <td>0.852801</td>\n",
       "      <td>0.675885</td>\n",
       "      <td>0.646561</td>\n",
       "      <td>0.707995</td>\n",
       "      <td>0.901855</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of predictions:  3981\n",
      "Number of predictions:  3981\n",
      "Number of predictions:  3981\n",
      "Number of predictions:  3981\n",
      "Number of predictions:  3981\n",
      "Number of predictions:  3981\n",
      "Number of predictions:  3981\n",
      "Number of predictions:  3981\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=13434, training_loss=0.3835945605912236, metrics={'train_runtime': 6941.5643, 'train_samples_per_second': 15.481, 'train_steps_per_second': 1.935, 'total_flos': 5.205505592381522e+16, 'train_loss': 0.3835945605912236, 'epoch': 3.0})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of predictions:  3981\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot a roc curve with sk learn  and matplot lib\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_roc_curve(trainer, tokenized_dataset):\n",
    "    output = trainer.predict(tokenized_dataset[\"valid\"])\n",
    "    labels = 1 - output.label_ids\n",
    "    pred_logits = output.predictions\n",
    "    pred_probs = torch.softmax(torch.tensor(pred_logits), dim=1)[:, 0].numpy()\n",
    "    fpr, tpr, thresholds = roc_curve(labels, pred_probs, pos_label=1)\n",
    "    plt.plot(fpr, tpr, label=f\"ROC curve (area = {auc(fpr, tpr):.2f})\")\n",
    "    return pred_probs, thresholds\n",
    "\n",
    "pred_probs, thres = plot_roc_curve(trainer, tokenized_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.2\n",
      "{'accuracy': 0.8480281336347651, 'f1': 0.6834118262689691, 'precision': 0.6230916030534351, 'recall': 0.7566628041714948, 'roc_auc': 0.9028888441278801}\n",
      "Threshold: 0.3\n",
      "{'accuracy': 0.8543079628234111, 'f1': 0.680968096809681, 'precision': 0.6481675392670158, 'recall': 0.7172653534183082, 'roc_auc': 0.9028888441278801}\n",
      "Threshold: 0.4\n",
      "{'accuracy': 0.8558151218286862, 'f1': 0.6742338251986381, 'precision': 0.660734149054505, 'recall': 0.6882966396292005, 'roc_auc': 0.9028888441278801}\n",
      "Threshold: 0.5\n",
      "{'accuracy': 0.8573222808339613, 'f1': 0.6716763005780347, 'precision': 0.6701268742791234, 'recall': 0.6732329084588644, 'roc_auc': 0.9028888441278801}\n",
      "Threshold: 0.6\n",
      "{'accuracy': 0.8580758603365989, 'f1': 0.6686217008797654, 'precision': 0.6769596199524941, 'recall': 0.660486674391657, 'roc_auc': 0.9028888441278801}\n",
      "Threshold: 0.7\n",
      "{'accuracy': 0.8605877920120573, 'f1': 0.6682606096832039, 'precision': 0.6901234567901234, 'recall': 0.6477404403244496, 'roc_auc': 0.9028888441278801}\n"
     ]
    }
   ],
   "source": [
    "# compute f1, precision, recall, and accuracy by given threshold\n",
    "def compute_metrics_with_threshold(pred_probs, thres, labels):\n",
    "    preds = (pred_probs > thres).astype(int)\n",
    "    result = {}\n",
    "    result.update(acc.compute(predictions=preds, references=labels))\n",
    "    result.update(f1.compute(predictions=preds, references=labels, average='binary', pos_label=1))\n",
    "    result.update(precision.compute(predictions=preds, references=labels, average='binary', pos_label=1))\n",
    "    result.update(recall.compute(predictions=preds, references=labels, average='binary', pos_label=1))\n",
    "    result.update(roc_auc_score.compute(prediction_scores=pred_probs, references=labels))\n",
    "    return result\n",
    "\n",
    "for t in [0.2, 0.3, 0.4, 0.5, 0.6, 0.7]:\n",
    "    print(f\"Threshold: {t}\")\n",
    "    print(compute_metrics_with_threshold(pred_probs, t, 1 - np.array(tokenized_dataset[\"valid\"][\"labels\"]).astype(int)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./dimiss_items/model/full/deberta-v3-large-1720902951/'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OUTPUT_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, tokenizer, output_dir):\n",
    "    model.save_pretrained(output_dir)\n",
    "    tokenizer.save_pretrained(output_dir)\n",
    "# OUTPUT_DIR = 'agents/dimiss_items/model/full/deberta-v3-large-1710086328/'\n",
    "save_model_path = OUTPUT_DIR + f\"deberta_v3_large_sample_{IS_TRAIN_SAMPLED}\"\n",
    "save_model(model, tokenizer, save_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cpkl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
