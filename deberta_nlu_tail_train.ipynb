{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iris/anaconda3/envs/cpkl/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset, DatasetDict, load_dataset\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from datasets import ClassLabel\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import nltk\n",
    "import evaluate\n",
    "import time\n",
    "\n",
    "\n",
    "# fix seeding for pytorch and huggingface\n",
    "import torch\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deberta NLU Tail Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset config\n",
    "linking_data_path = \"./dimiss_items/data/model_gpt-3.5-turbo-0125\"\n",
    "TRAIN_DATA_PATH = f'{linking_data_path}/processed/gpt_label_full_train_df.json'\n",
    "VALID_DATA_PATH = f'{linking_data_path}/processed/gpt_label_full_valid_df.json'\n",
    "\n",
    "DS_TYPE = \"tail\"\n",
    "USE_TAG = True\n",
    "\n",
    "LABEL_TO_ID = {\"entailment\": 0, \"not_entailment\": 1}\n",
    "ID_TO_LABEL = {0: \"entailment\", 1: \"not_entailment\"}\n",
    "\n",
    "COMFACT_LABEL_TO_ID = {True: 0, False: 1} # comFactDataLabelToId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def replace_phrases(sentence, person_a_tag):\n",
    "    sentence = sentence.lower()\n",
    "    # Pattern to find \"I am\" and replace with \"person a is\"\n",
    "    sentence = re.sub(r\"\\bi am\\b\", f\"{person_a_tag} is\", sentence, flags=re.IGNORECASE)\n",
    "    # Pattern to find \"I was\" and replace with \"person a was\"\n",
    "    sentence = re.sub(r\"\\bi was\\b\", f\"{person_a_tag} was\", sentence, flags=re.IGNORECASE)\n",
    "    sentence = re.sub(r\"\\bi\\b\", person_a_tag, sentence, flags=re.IGNORECASE)\n",
    "    sentence = re.sub(r\"\\bmy\\b\", f\"{person_a_tag}'s\", sentence, flags=re.IGNORECASE)\n",
    "    sentence = sentence.replace('person a', person_a_tag)\n",
    "    return sentence\n",
    "\n",
    "\n",
    "class DatasetLoader:\n",
    "    def __init__(self, train_data_path: str, valid_data_path: str, ds_type: str, sample_size: int = None):\n",
    "        self.train_data_path = train_data_path\n",
    "        self.valid_data_path = valid_data_path\n",
    "        self.sample_size = sample_size\n",
    "        self.pa_tag, self.pb_tag = 'Person A', 'Person B'\n",
    "        self.ds_type = ds_type\n",
    "\n",
    "    def get_conv_from_text(self, example):\n",
    "        center_utter = \"\"\n",
    "        post_utters, future_utters = [], []\n",
    "        for x in example['text']:\n",
    "            if x['type'] == 'ut':\n",
    "                center_utter = x['utter']\n",
    "            elif '-' in x['type']:\n",
    "                post_utters.append(x['utter'])\n",
    "            elif '+' in x['type']:\n",
    "                future_utters.append(x['utter'])\n",
    "\n",
    "        convs_list = '\\n'.join(post_utters + [center_utter] + future_utters)\n",
    "        return convs_list\n",
    "\n",
    "    def get_conv_with_tag_from_text(self, example):\n",
    "        def format_utter(utter, tag):\n",
    "            if utter.strip() == '':\n",
    "                return ''\n",
    "            return f\"{tag}: {utter}\"\n",
    "        center_utter = \"\"\n",
    "        post_utters, future_utters = [], []\n",
    "        for x in example['text']:\n",
    "            if x['type'] == 'ut':\n",
    "                center_utter = format_utter(x['utter'], self.pa_tag)\n",
    "            elif '-1' in x['type']:\n",
    "                post_utters.append(format_utter(x['utter'], self.pb_tag))\n",
    "            elif '-2' in x['type']:\n",
    "                post_utters.append(format_utter(x['utter'], self.pa_tag)) \n",
    "            elif '+1' in x['type']:\n",
    "                future_utters.append(format_utter(x['utter'], self.pb_tag)) \n",
    "            elif '+2' in x['type']:\n",
    "                future_utters.append(format_utter(x['utter'], self.pa_tag)) \n",
    "\n",
    "        convs_list = '\\n'.join(post_utters + [center_utter] + future_utters)\n",
    "        return convs_list #.lower()\n",
    "\n",
    "    def transform_df(self, df):\n",
    "        df['conv'] = df.apply(self.get_conv_from_text, axis=1) if not USE_TAG else df.apply(self.get_conv_with_tag_from_text, axis=1)\n",
    "        df['fact_text'] = df['fact_text'].apply(lambda x: x) if not USE_TAG else df['fact_text'].apply(lambda x: replace_phrases(x, self.pa_tag))\n",
    "        df['labels'] = df['gold_reference'].apply(lambda x: COMFACT_LABEL_TO_ID[x])\n",
    "        df['label_text'] = df['labels'].apply(lambda x: ID_TO_LABEL[x].lower())\n",
    "        return df\n",
    "\n",
    "    def create_pd_dataframe(self, data_path, sample_size=None):\n",
    "        df = pd.read_json(data_path)\n",
    "        # if self.ds_type == \"relation\":\n",
    "        #     df['peacok_relation'] = df['relation']\n",
    "        # if 'merged_head_tail' in data_path:\n",
    "        #     df = self.modify_merged_head_tail(df)\n",
    "        df = self.modify_merged_head_tail(df)\n",
    "        df = df.sample(sample_size) if sample_size else df\n",
    "        df = self.transform_df(df)\n",
    "        return df\n",
    "\n",
    "    def create_dataset(self, train_df, valid_df):\n",
    "        train_ds = Dataset.from_pandas(train_df)\n",
    "        valid_ds = Dataset.from_pandas(valid_df)\n",
    "\n",
    "        dataset = DatasetDict({\n",
    "            'train': train_ds,\n",
    "            'valid': valid_ds\n",
    "        })\n",
    "        return dataset\n",
    "    \n",
    "    # def get_relation(self, df):\n",
    "    #     return origonal_peacok_relation_df[origonal_peacok_relation_df['dialog_id'].isin(df['dialog_id'])]['peacok_relation']\n",
    "    \n",
    "    def modify_merged_head_tail(self, df):\n",
    "        if self.ds_type == \"head\":\n",
    "            df['gold_reference'] = df['gpt_tagged_head_gold_reference']\n",
    "            df['fact_text'] = df['gpt_tagged_head_fact_text']\n",
    "        elif self.ds_type == \"tail\":\n",
    "            df['gold_reference'] = df['gpt_tagged_tail_gold_reference']\n",
    "            df['fact_text'] = df['gpt_tagged_tail_fact_text']\n",
    "        elif self.ds_type == \"relation\":\n",
    "            # assert df['head_text'].equals(df['tail_text']), \"head and tail text should be the same\"\n",
    "            # df['text'] = df['tail_text']\n",
    "            df['gold_reference'] = df['gpt_tagged_head_gold_reference'] & df['gpt_tagged_tail_gold_reference']\n",
    "            df['fact_text'] = df.apply(lambda x: f\"{x['relation']} {x['gpt_tagged_head_fact_text']} and {x['gpt_tagged_tail_fact_text']}\", axis=1)\n",
    "            # df['fact_text'] = df.apply(lambda x: f\"{x['head_fact_text']} and {x['tail_fact_text']}; {x['peacok_relation']}\", axis=1)\n",
    "        else:\n",
    "            # assert df['head_text'].equals(df['tail_text']), \"head and tail text should be the same\"\n",
    "            # df['text'] = df['tail_text']\n",
    "            df['gold_reference'] = df['gpt_tagged_head_gold_reference'] & df['gpt_tagged_tail_gold_reference']\n",
    "            df['fact_text'] = df.apply(lambda x: f\"{x['gpt_tagged_head_fact_text']} and {x['gpt_tagged_tail_fact_text']}\", axis=1)\n",
    "        return df\n",
    "\n",
    "    def load(self):\n",
    "        train_df = self.create_pd_dataframe(self.train_data_path) # create_pd_dataframe(TRAIN_DATA_PATH, 5000)\n",
    "        valid_df = self.create_pd_dataframe(self.valid_data_path) # create_pd_dataframe(VALID_DATA_PATH, 500)\n",
    "        dataset = self.create_dataset(train_df, valid_df)\n",
    "        return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['dialog_id', 'relation', 'head', 'tail', 'text', 'gpt_tagged_head_old_label', 'gpt_tagged_head_gpt_output', 'gpt_tagged_head_fact_text', 'gpt_tagged_head_gold_reference', 'gpt_tagged_tail_gpt_output', 'gpt_tagged_tail_old_label', 'gpt_tagged_tail_action', 'gpt_tagged_tail_fact_text', 'gpt_tagged_tail_gold_reference', 'gold_reference', 'fact_text', 'conv', 'labels', 'label_text', '__index_level_0__'],\n",
       "        num_rows: 35821\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['dialog_id', 'relation', 'head', 'tail', 'text', 'gpt_tagged_head_old_label', 'gpt_tagged_head_gpt_output', 'gpt_tagged_head_fact_text', 'gpt_tagged_head_gold_reference', 'gpt_tagged_tail_gpt_output', 'gpt_tagged_tail_old_label', 'gpt_tagged_tail_action', 'gpt_tagged_tail_fact_text', 'gpt_tagged_tail_gold_reference', 'gold_reference', 'fact_text', 'conv', 'labels', 'label_text', '__index_level_0__'],\n",
       "        num_rows: 3981\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataset\n",
    "dataset_loader = DatasetLoader(TRAIN_DATA_PATH, VALID_DATA_PATH, DS_TYPE)\n",
    "dataset = dataset_loader.load()\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'additional_special_tokens': ['characteristic_relationship',\n",
       "  'goal_plan_relationship',\n",
       "  'goal_plan',\n",
       "  'routine_habit',\n",
       "  'experience_relationship',\n",
       "  'routine_habit_relationship',\n",
       "  'characteristic',\n",
       "  'experience']}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use train_ds and valid_ds to get all unique relations for specical tokenization\n",
    "relations_tokens = set(dataset['train']['relation'] + dataset['valid']['relation'])\n",
    "relations_special_tokens = {'additional_special_tokens': list(relations_tokens)}\n",
    "relations_special_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tail ds train len is 35821\n",
      "tail Positive: 21563(0.6019653276011279)\n",
      "tail Negative: 14258(0.3980346723988722)\n",
      "\n",
      "tail ds valid len is 3981\n",
      "tail Positive: 2378(0.5973373524240141)\n",
      "tail Negative: 1603(0.4026626475759859)\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "counter = Counter([example['gold_reference'] for example in dataset['train']])\n",
    "valid_counter = Counter([example['gold_reference'] for example in dataset['valid']])\n",
    "\n",
    "print(f\"{DS_TYPE} ds train len is {len(dataset['train'])}\")\n",
    "print(f\"{DS_TYPE} Positive: {counter[True]}({counter[True]/len(dataset['train'])})\")\n",
    "print(f\"{DS_TYPE} Negative: {counter[False]}({counter[False]/len(dataset['train'])})\")\n",
    "print()\n",
    "print(f\"{DS_TYPE} ds valid len is {len(dataset['valid'])}\")\n",
    "print(f\"{DS_TYPE} Positive: {valid_counter[True]}({valid_counter[True]/len(dataset['valid'])})\")\n",
    "print(f\"{DS_TYPE} Negative: {valid_counter[False]}({valid_counter[False]/len(dataset['valid'])})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Person A: i don't have hair. i want to go to vegas. how are you? just to let you know i'm single.\n",
      "Person B: are you male or female? i can not wait to go back to school. do you use a wig? winter and fall is my favorite season\n",
      "Person A: i saw a wig on netflix. fall isn't that good. male, college? you do sleeping in? i do\n",
      "Person B: my sister loves me, and i love her. we are best friends. why not? does it get you down?\n",
      "Person A: it is just that in vegas fall causes weird people to come out. you saw right? i'm happy for you. love is so hard to come by. \n",
      "\n",
      "am always there for friends\n",
      "Person A is a loyal person\n",
      "None\n",
      "routine_habit_relationship\n",
      "am always there for friends\n"
     ]
    }
   ],
   "source": [
    "print(dataset['train'][0]['conv'], '\\n')\n",
    "print(dataset['train'][0]['gpt_tagged_tail_fact_text'])\n",
    "print(dataset['train'][0]['gpt_tagged_head_fact_text'])\n",
    "print(dataset['train'][0]['gpt_tagged_tail_action'])\n",
    "print(dataset['train'][0]['relation'])\n",
    "print(dataset['train'][0]['fact_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "- Model Name: microsoft/deberta-v3-large\n",
      "- Model Size: large\n",
      "- Ds Type: tail\n",
      "- Output Dir: ./dimiss_items/model/tail/deberta-v3-large-1720894757/\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mirislin1006\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/c/Users/iris/Desktop/wsl_shared/CPKL/wandb/run-20240713_131918-gq2kqks9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/irislin1006/cpkl-tail-microsoft-deberta-v3-large/runs/gq2kqks9' target=\"_blank\">deberta-v3-large-tail</a></strong> to <a href='https://wandb.ai/irislin1006/cpkl-tail-microsoft-deberta-v3-large' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/irislin1006/cpkl-tail-microsoft-deberta-v3-large' target=\"_blank\">https://wandb.ai/irislin1006/cpkl-tail-microsoft-deberta-v3-large</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/irislin1006/cpkl-tail-microsoft-deberta-v3-large/runs/gq2kqks9' target=\"_blank\">https://wandb.ai/irislin1006/cpkl-tail-microsoft-deberta-v3-large/runs/gq2kqks9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/irislin1006/cpkl-tail-microsoft-deberta-v3-large/runs/gq2kqks9?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7ff26f474100>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load model config\n",
    "IS_TRAIN_SAMPLED = False\n",
    "MODEL_SIZE = \"large\"\n",
    "MODEL_NAME = f\"microsoft/deberta-v3-{MODEL_SIZE}\"\n",
    "# MODEL_NAME = f\"MoritzLaurer/deberta-v3-large-zeroshot-v1.1-all-33\"\n",
    "OUTPUT_DIR = f\"./dimiss_items/model/{DS_TYPE}/deberta-v3-{MODEL_SIZE}-{str(int(time.time()))}/\"\n",
    "\n",
    "print(f\"\"\"\n",
    "- Model Name: {MODEL_NAME}\n",
    "- Model Size: {MODEL_SIZE}\n",
    "- Ds Type: {DS_TYPE}\n",
    "- Output Dir: {OUTPUT_DIR}\n",
    "\"\"\")\n",
    "\n",
    "import wandb\n",
    "wandb.init(project=f\"cpkl-{DS_TYPE}-{MODEL_NAME.replace('/', '-')}\", name=f\"deberta-v3-{MODEL_SIZE}-{DS_TYPE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_and_tokenizer(model_name, label2id, id2label):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=False, model_max_length=512)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_name, label2id=label2id, id2label=id2label)\n",
    "    \n",
    "    if DS_TYPE == \"relation\":\n",
    "        tokenizer.add_special_tokens(relations_special_tokens)\n",
    "        model.resize_token_embeddings(len(tokenizer))\n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iris/anaconda3/envs/cpkl/lib/python3.9/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=False, model_max_length=512)\n",
    "# model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, label2id=label2id, id2label=id2label)\n",
    "model, tokenizer = load_model_and_tokenizer(MODEL_NAME, LABEL_TO_ID, ID_TO_LABEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Dataset for trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 35821/35821 [00:11<00:00, 3075.82 examples/s]\n",
      "Map: 100%|██████████| 3981/3981 [00:01<00:00, 3064.00 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using tail Dataset. Keys of tokenized dataset: ['labels', 'label_text', 'input_ids', 'token_type_ids', 'attention_mask']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def tokenize_function(examples):\n",
    "   return tokenizer(examples[\"conv\"], examples[\"fact_text\"], padding=True, truncation=True, max_length=512)\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize_function, batched=True, remove_columns=[\n",
    "   'dialog_id', \n",
    "   'text',\n",
    "   'relation',\n",
    "   'head',\n",
    "   'tail',\n",
    "   'gpt_tagged_head_old_label', \n",
    "   'gpt_tagged_head_gold_reference', \n",
    "   'gpt_tagged_head_fact_text', \n",
    "   'gpt_tagged_head_gpt_output', \n",
    "   'gpt_tagged_tail_old_label', \n",
    "   'gpt_tagged_tail_gold_reference', \n",
    "   'gpt_tagged_tail_fact_text', \n",
    "   'gpt_tagged_tail_gpt_output', \n",
    "   'gpt_tagged_tail_action', \n",
    "   'fact_text', \n",
    "   'gold_reference', \n",
    "   'conv',\n",
    "   '__index_level_0__'])\n",
    "print(f\"Using {DS_TYPE} Dataset. Keys of tokenized dataset: {list(tokenized_dataset['train'].features)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare trainer\n",
    "\n",
    "acc = evaluate.load(\"accuracy\")\n",
    "f1 = evaluate.load(\"f1\")\n",
    "precision = evaluate.load(\"precision\")\n",
    "recall = evaluate.load(\"recall\")\n",
    "roc_auc_score = evaluate.load(\"roc_auc\")\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    labels = eval_preds.label_ids\n",
    "    pred_logits = eval_preds.predictions\n",
    "    preds_max = np.argmax(pred_logits, axis=1)  # argmax on each row (axis=1) in the tensor\n",
    "    pred_probs = torch.softmax(torch.tensor(pred_logits), dim=1)[:, 0].numpy()\n",
    "      \n",
    "    print(\"Number of predictions: \", len(preds_max))\n",
    "    # compute f1, precision, recall, and accuracy \n",
    "    result = {}\n",
    "    result.update(acc.compute(predictions=preds_max, references=labels))\n",
    "    result.update(f1.compute(predictions=preds_max, references=labels, average='binary', pos_label=0))\n",
    "    result.update(precision.compute(predictions=preds_max, references=labels, average='binary', pos_label=0))\n",
    "    result.update(recall.compute(predictions=preds_max, references=labels, average='binary', pos_label=0))\n",
    "    result.update(roc_auc_score.compute(prediction_scores=pred_probs, references=1-labels))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trainer_args(output_dir):\n",
    "    if DS_TYPE == \"full\":\n",
    "        eval_steps=1500\n",
    "        save_steps=1500\n",
    "    elif DS_TYPE == \"head\":\n",
    "        eval_steps=3000\n",
    "        save_steps=3000\n",
    "    elif DS_TYPE == \"tail\":\n",
    "        eval_steps=3000\n",
    "        save_steps=3000\n",
    "    elif DS_TYPE == \"relation\":\n",
    "        # eval_steps=500\n",
    "        # save_steps=500\n",
    "        eval_steps=1500\n",
    "        save_steps=1500\n",
    "    else:\n",
    "        raise ValueError(f\"'{DS_TYPE}' is invalid dataset type. Must be one of 'full', 'head', 'tail'\")\n",
    "    \n",
    "    return TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        per_device_train_batch_size=8,\n",
    "        per_device_eval_batch_size=8,\n",
    "        bf16 =False, # Overflows with bf16 \n",
    "        learning_rate=1e-6,\n",
    "        warmup_ratio=0.01,\n",
    "        weight_decay=0.01,\n",
    "        num_train_epochs=3,\n",
    "        # logging & evaluation strategies\n",
    "        logging_dir=f\"{output_dir}/logs\",\n",
    "        logging_strategy=\"steps\", \n",
    "        logging_steps=20,\n",
    "        evaluation_strategy=\"steps\",\n",
    "        eval_steps=eval_steps,\n",
    "        save_strategy=\"steps\",\n",
    "        save_steps=save_steps,\n",
    "        save_total_limit=5,\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"roc_auc\",\n",
    "        # push to hub parameters\n",
    "        report_to=\"wandb\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trainer(model, tokenized_dataset, output_dir):\n",
    "    training_args = get_trainer_args(output_dir)\n",
    "    trainer =Trainer(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_dataset[\"train\"],\n",
    "        eval_dataset=tokenized_dataset[\"valid\"],\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "    return trainer\n",
    "\n",
    "trainer = get_trainer(model, tokenized_dataset, OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13434' max='13434' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13434/13434 1:47:37, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Roc Auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.488800</td>\n",
       "      <td>0.543001</td>\n",
       "      <td>0.750314</td>\n",
       "      <td>0.801597</td>\n",
       "      <td>0.762918</td>\n",
       "      <td>0.844407</td>\n",
       "      <td>0.800804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.554500</td>\n",
       "      <td>0.530456</td>\n",
       "      <td>0.759608</td>\n",
       "      <td>0.810382</td>\n",
       "      <td>0.766205</td>\n",
       "      <td>0.859966</td>\n",
       "      <td>0.824882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.418200</td>\n",
       "      <td>0.514371</td>\n",
       "      <td>0.771917</td>\n",
       "      <td>0.814391</td>\n",
       "      <td>0.792363</td>\n",
       "      <td>0.837679</td>\n",
       "      <td>0.835008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.475800</td>\n",
       "      <td>0.510756</td>\n",
       "      <td>0.769907</td>\n",
       "      <td>0.813594</td>\n",
       "      <td>0.788249</td>\n",
       "      <td>0.840622</td>\n",
       "      <td>0.836518</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of predictions:  3981\n",
      "Number of predictions:  3981\n",
      "Number of predictions:  3981\n",
      "Number of predictions:  3981\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=13434, training_loss=0.5313465964036345, metrics={'train_runtime': 6478.3637, 'train_samples_per_second': 16.588, 'train_steps_per_second': 2.074, 'total_flos': 5.074214870844216e+16, 'train_loss': 0.5313465964036345, 'epoch': 3.0})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of predictions:  3981\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot a roc curve with sk learn  and matplot lib\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_roc_curve(trainer, tokenized_dataset):\n",
    "    output = trainer.predict(tokenized_dataset[\"valid\"])\n",
    "    labels = 1 - output.label_ids\n",
    "    pred_logits = output.predictions\n",
    "    pred_probs = torch.softmax(torch.tensor(pred_logits), dim=1)[:, 0].numpy()\n",
    "    fpr, tpr, thresholds = roc_curve(labels, pred_probs, pos_label=1)\n",
    "    plt.plot(fpr, tpr, label=f\"ROC curve (area = {auc(fpr, tpr):.2f})\")\n",
    "    return pred_probs, thresholds\n",
    "\n",
    "pred_probs, thres = plot_roc_curve(trainer, tokenized_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.2\n",
      "{'accuracy': 0.7415222305953278, 'f1': 0.8119173825626029, 'precision': 0.718073068218558, 'recall': 0.9339781328847772, 'roc_auc': 0.8365177623746896}\n",
      "Threshold: 0.3\n",
      "{'accuracy': 0.7578497864858076, 'f1': 0.8161007249141548, 'precision': 0.7468575418994413, 'recall': 0.8994953742640874, 'roc_auc': 0.8365177623746896}\n",
      "Threshold: 0.4\n",
      "{'accuracy': 0.765134388344637, 'f1': 0.8161981521525458, 'precision': 0.7663344407530454, 'recall': 0.8730025231286795, 'roc_auc': 0.8365177623746896}\n",
      "Threshold: 0.5\n",
      "{'accuracy': 0.769907058528008, 'f1': 0.8135938135938136, 'precision': 0.7882492113564669, 'recall': 0.8406223717409588, 'roc_auc': 0.8365177623746896}\n",
      "Threshold: 0.6\n",
      "{'accuracy': 0.7678975131876413, 'f1': 0.8062080536912752, 'precision': 0.80418410041841, 'recall': 0.808242220353238, 'roc_auc': 0.8365177623746896}\n",
      "Threshold: 0.7\n",
      "{'accuracy': 0.7623712635016328, 'f1': 0.7949718248807975, 'precision': 0.8202146690518783, 'recall': 0.7712363330529857, 'roc_auc': 0.8365177623746896}\n"
     ]
    }
   ],
   "source": [
    "# compute f1, precision, recall, and accuracy by given threshold\n",
    "def compute_metrics_with_threshold(pred_probs, thres, labels):\n",
    "    preds = (pred_probs > thres).astype(int)\n",
    "    result = {}\n",
    "    result.update(acc.compute(predictions=preds, references=labels))\n",
    "    result.update(f1.compute(predictions=preds, references=labels, average='binary', pos_label=1))\n",
    "    result.update(precision.compute(predictions=preds, references=labels, average='binary', pos_label=1))\n",
    "    result.update(recall.compute(predictions=preds, references=labels, average='binary', pos_label=1))\n",
    "    result.update(roc_auc_score.compute(prediction_scores=pred_probs, references=labels))\n",
    "    return result\n",
    "\n",
    "for t in [0.2, 0.3, 0.4, 0.5, 0.6, 0.7]:\n",
    "    print(f\"Threshold: {t}\")\n",
    "    print(compute_metrics_with_threshold(pred_probs, t, 1 - np.array(tokenized_dataset[\"valid\"][\"labels\"]).astype(int)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./dimiss_items/model/tail/deberta-v3-large-1720894757/'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OUTPUT_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, tokenizer, output_dir):\n",
    "    model.save_pretrained(output_dir)\n",
    "    tokenizer.save_pretrained(output_dir)\n",
    "# OUTPUT_DIR = 'agents/dimiss_items/model/full/deberta-v3-large-1710086328/'\n",
    "save_model_path = OUTPUT_DIR + f\"deberta_v3_large_sample_{IS_TRAIN_SAMPLED}\"\n",
    "save_model(model, tokenizer, save_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cpkl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
