{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from huggingface_hub import PyTorchModelHubMixin\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload model and datasets to huggingface hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model source to be uploaded to huggingface hub\n",
    "model_path = \"./models/full/nlu/deberta_v3_large_sample_False\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iris/anaconda3/envs/cpkl/lib/python3.9/site-packages/transformers/convert_slow_tokenizer.py:515: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# need to add tok into final_model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model.safetensors: 100%|██████████| 1.74G/1.74G [02:28<00:00, 11.7MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/theirislin/deberta-v3-large-peacock-knowledge-linking/commit/1e74e2d4cdd4455d1e89dcf3541df6e47190c2e3', commit_message='Upload DebertaV2ForSequenceClassification', commit_description='', oid='1e74e2d4cdd4455d1e89dcf3541df6e47190c2e3', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = 'deberta-v3-large-peacock-knowledge-linking'\n",
    "model.push_to_hub(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "README.md: 100%|██████████| 5.18k/5.18k [00:00<00:00, 2.77MB/s]\n",
      "spm.model: 100%|██████████| 2.46M/2.46M [00:00<00:00, 4.45MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/theirislin/deberta-v3-large-peacock-knowledge-linking/commit/c854b1b45b1fb2eb3a442b0b672d584673009a5f', commit_message='Upload tokenizer', commit_description='', oid='c854b1b45b1fb2eb3a442b0b672d584673009a5f', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.push_to_hub(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict, load_dataset\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from datasets import ClassLabel\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import nltk\n",
    "import evaluate\n",
    "import time\n",
    "\n",
    "\n",
    "# fix seeding for pytorch and huggingface\n",
    "import torch\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data set config\n",
    "linking_data_path = \"./dimiss_items/data/gpt_annotated_peacok/model_gpt-3.5-turbo-0125\"\n",
    "TRAIN_DATA_PATH = f'{linking_data_path}/merged_head_tail_train_data_35k.json'\n",
    "VALID_DATA_PATH = f'{linking_data_path}/merged_head_tail_val_data_4k.json'\n",
    "# TRAIN_DATA_PATH = f'{linking_data_path}/model_label_head_train_df_0229.json'\n",
    "# VALID_DATA_PATH = f'{linking_data_path}/model_label_head_valid_df_0229.json'\n",
    "# TRAIN_DATA_PATH = f'{linking_data_path}/model_label_train_0229.json'\n",
    "# VALID_DATA_PATH = f'{linking_data_path}/model_label_valid.json'\n",
    "# linking_data_path = \"./dimiss_items/data/comFact/\"\n",
    "# TRAIN_DATA_PATH = f'{linking_data_path}/augmented_train_data.json'\n",
    "# VALID_DATA_PATH = f'{linking_data_path}/augmented_val_data.json'\n",
    "\n",
    "DS_TYPE = \"relation\" # \"full\" or \"head\" or \"tail\"\n",
    "USE_TAG = True\n",
    "\n",
    "LABEL_TO_ID = {\"entailment\": 0, \"not_entailment\": 1}\n",
    "ID_TO_LABEL = {0: \"entailment\", 1: \"not_entailment\"}\n",
    "\n",
    "COMFACT_LABEL_TO_ID = {True: 0, False: 1} # comFactDataLabelToId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original_head_tagged_df (39802, 16)\n",
      "original_tail_tagged_df (39802, 17)\n",
      "original_tagged_df (39802, 32)\n",
      "origonal_peacok_relation_df (39802, 2)\n",
      "all predefined relations peacok_relation\n",
      "routine_habit                  14825\n",
      "characteristic                  8808\n",
      "experience                      6948\n",
      "routine_habit_relationship      4918\n",
      "goal_plan                       2459\n",
      "experience_relationship          964\n",
      "goal_plan_relationship           485\n",
      "characteristic_relationship      395\n",
      "Name: count, dtype: int64\n",
      "relations {'additional_special_tokens': ['routine_habit', 'experience', 'characteristic', 'routine_habit_relationship', 'goal_plan', 'characteristic_relationship', 'experience_relationship', 'goal_plan_relationship']}\n",
      "original_gpt_tagged_df (39802, 3)\n"
     ]
    }
   ],
   "source": [
    "def get_peacok_relation_label(relation):\n",
    "    tdf = pd.read_json(VALID_DATA_PATH)\n",
    "\n",
    "    original_head_tagged_df = pd.read_json(f'{linking_data_path}/head_annotation_sample40000_1709689043.json')\n",
    "    original_tail_tagged_df = pd.read_json(f'{linking_data_path}/tail_annotation_sample40000_1709657696.json')\n",
    "    print(\"original_head_tagged_df\", original_head_tagged_df.shape)\n",
    "    print(\"original_tail_tagged_df\", original_tail_tagged_df.shape)\n",
    "    # Merge 2 original dfs on column dialogue_id\n",
    "    original_tagged_df = pd.merge(original_head_tagged_df, original_tail_tagged_df, on='dialog_id')\n",
    "    print(\"original_tagged_df\", original_tagged_df.shape)\n",
    "\n",
    "    # create a relation between dialogue_id and dialogue\n",
    "    origonal_peacok_relation_df = original_tagged_df[['dialog_id', 'relation_x']].rename(columns={'relation_x': 'peacok_relation'})\n",
    "    print(\"origonal_peacok_relation_df\", origonal_peacok_relation_df.shape)\n",
    "    print(\"all predefined relations\", origonal_peacok_relation_df['peacok_relation'].value_counts())\n",
    "    return origonal_peacok_relation_df\n",
    "\n",
    "def get_gpt_tagged_raw_data():\n",
    "    # Load the data\n",
    "    head_df = pd.read_json(\"./dimiss_items/data/gpt_annotated_peacok/model_gpt-3.5-turbo-0125/head_annotation_sample40000_1709689043.json\")\n",
    "    head_df = head_df.rename(columns={'gp_output': 'gpt_output_head'})\n",
    "    # print(\"head_df\", head_df.columns)\n",
    "    tail_df = pd.read_json(\"./dimiss_items/data/gpt_annotated_peacok/model_gpt-3.5-turbo-0125/tail_annotation_sample40000_1709657696.json\")\n",
    "    tail_df = tail_df.rename(columns={'gp_output': 'gpt_output_tail'})\n",
    "    # print(\"tail_df\", tail_df.shape)\n",
    "\n",
    "    # Merge 2 original dfs on column dialogue_id\n",
    "    original_gpt_tagged_df = pd.merge(head_df, tail_df, on='dialog_id')\n",
    "    original_gpt_tagged_df = original_gpt_tagged_df[['dialog_id', 'gpt_output_head', 'gpt_output_tail']]\n",
    "    print(\"original_gpt_tagged_df\", original_gpt_tagged_df.shape)\n",
    "    # print(\"original_gpt_tagged_df\", original_gpt_tagged_df.columns)\n",
    "    return original_gpt_tagged_df\n",
    "\n",
    "\n",
    "if DS_TYPE == \"relation\":\n",
    "    origonal_peacok_relation_df = get_peacok_relation_label(\"relation\")\n",
    "    # create a list of all the relations\n",
    "    relations = origonal_peacok_relation_df['peacok_relation'].unique()\n",
    "    relations_special_tokens = {'additional_special_tokens': relations.tolist()}\n",
    "    print(\"relations\", relations_special_tokens)\n",
    "\n",
    "    original_gpt_tagged_df = get_gpt_tagged_raw_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def replace_phrases(sentence, person_a_tag):\n",
    "    sentence = sentence.lower()\n",
    "    # Pattern to find \"I am\" and replace with \"person a is\"\n",
    "    sentence = re.sub(r\"\\bi am\\b\", f\"{person_a_tag} is\", sentence, flags=re.IGNORECASE)\n",
    "    # Pattern to find \"I was\" and replace with \"person a was\"\n",
    "    sentence = re.sub(r\"\\bi was\\b\", f\"{person_a_tag} was\", sentence, flags=re.IGNORECASE)\n",
    "    sentence = re.sub(r\"\\bi\\b\", person_a_tag, sentence, flags=re.IGNORECASE)\n",
    "    sentence = re.sub(r\"\\bmy\\b\", f\"{person_a_tag}'s\", sentence, flags=re.IGNORECASE)\n",
    "    sentence = sentence.replace('person a', person_a_tag)\n",
    "    return sentence\n",
    "\n",
    "\n",
    "class DatasetLoader:\n",
    "    def __init__(self, train_data_path: str, valid_data_path: str, ds_type: str, sample_size: int = None):\n",
    "        self.train_data_path = train_data_path\n",
    "        self.valid_data_path = valid_data_path\n",
    "        self.sample_size = sample_size\n",
    "        self.pa_tag, self.pb_tag = 'Person A', 'Person B'\n",
    "        self.ds_type = ds_type\n",
    "\n",
    "    def transform_df(self, df):\n",
    "        print(\"transforming df\", df.columns)\n",
    "        df['label'] = df['gold_reference'].apply(lambda x: COMFACT_LABEL_TO_ID[x])\n",
    "        \n",
    "        assert df['head_text'].equals(df['tail_text']), \"head and tail text should be the same\"\n",
    "        assert df['head_text'].equals(df['text']), \"head and text should be the same\"\n",
    "\n",
    "        # Clean up the df\n",
    "        df = df.rename(\n",
    "            columns={\n",
    "                'head_text': 'dialog_dict', # head_text is the same as tail_text, both dialog\n",
    "                'head_gold_reference': 'head_label',\n",
    "                'tail_gold_reference': 'tail_label',\n",
    "                }\n",
    "            )\n",
    "        final_columns = [\n",
    "            'dialog_id', 'dialog_dict', 'head_label', 'head_fact_text', 'gpt_output_head',\n",
    "            'tail_label', 'tail_fact_text',  'gpt_output_tail', 'peacok_relation', 'label'\n",
    "        ]\n",
    "        df = df[final_columns]\n",
    "        return df\n",
    "\n",
    "    def create_pd_dataframe(self, data_path, sample_size=None):\n",
    "        df = pd.read_json(data_path)\n",
    "        if self.ds_type == \"relation\":\n",
    "            df['peacok_relation'] = self.get_relation(df)\n",
    "            gpt_tagged_df = self.get_gpt_tagged_raw_data(df)\n",
    "            df['gpt_output_head'] = gpt_tagged_df['gpt_output_head']\n",
    "            df['gpt_output_tail'] = gpt_tagged_df['gpt_output_tail']\n",
    "        if 'merged_head_tail' in data_path:\n",
    "            df = self.modify_merged_head_tail(df)\n",
    "        df = df.sample(sample_size) if sample_size else df\n",
    "        df = self.transform_df(df)\n",
    "        return df\n",
    "\n",
    "    def create_dataset(self, train_df, valid_df):\n",
    "        train_ds = Dataset.from_pandas(train_df).remove_columns(['__index_level_0__'])\n",
    "        valid_ds = Dataset.from_pandas(valid_df).remove_columns(['__index_level_0__'])\n",
    "\n",
    "        dataset = DatasetDict({\n",
    "            'train': train_ds,\n",
    "            'valid': valid_ds\n",
    "        })\n",
    "        return dataset\n",
    "    \n",
    "    def get_relation(self, df):\n",
    "        return origonal_peacok_relation_df[origonal_peacok_relation_df['dialog_id'].isin(df['dialog_id'])]['peacok_relation']\n",
    "    \n",
    "    def get_gpt_tagged_raw_data(self, df):\n",
    "        return original_gpt_tagged_df[original_gpt_tagged_df['dialog_id'].isin(df['dialog_id'])][['gpt_output_head', 'gpt_output_tail']]\n",
    "    \n",
    "    def modify_merged_head_tail(self, df):\n",
    "        if self.ds_type == \"head\":\n",
    "            df['text'] = df['head_text']\n",
    "            df['gold_reference'] = df['head_gold_reference']\n",
    "            df['fact_text'] = df['head_fact_text']\n",
    "        elif self.ds_type == \"tail\":\n",
    "            df['text'] = df['tail_text']\n",
    "            df['gold_reference'] = df['tail_gold_reference']\n",
    "            df['fact_text'] = df['tail_fact_text']\n",
    "        elif self.ds_type == \"relation\":\n",
    "            assert df['head_text'].equals(df['tail_text']), \"head and tail text should be the same\"\n",
    "            df['text'] = df['tail_text']\n",
    "            df['gold_reference'] = df['head_gold_reference'] & df['tail_gold_reference']\n",
    "            df['fact_text'] = df.apply(lambda x: f\"{x['peacok_relation']} {x['head_fact_text']} and {x['tail_fact_text']}\", axis=1)\n",
    "            # df['fact_text'] = df.apply(lambda x: f\"{x['head_fact_text']} and {x['tail_fact_text']}; {x['peacok_relation']}\", axis=1)\n",
    "        else:\n",
    "            assert df['head_text'].equals(df['tail_text']), \"head and tail text should be the same\"\n",
    "            df['text'] = df['tail_text']\n",
    "            df['gold_reference'] = df['head_gold_reference'] & df['tail_gold_reference']\n",
    "            df['fact_text'] = df.apply(lambda x: f\"{x['head_fact_text']} and {x['tail_fact_text']}\", axis=1)\n",
    "        return df\n",
    "\n",
    "    def load(self):\n",
    "        train_df = self.create_pd_dataframe(self.train_data_path) # create_pd_dataframe(TRAIN_DATA_PATH, 5000)\n",
    "        valid_df = self.create_pd_dataframe(self.valid_data_path) # create_pd_dataframe(VALID_DATA_PATH, 500)\n",
    "        dataset = self.create_dataset(train_df, valid_df)\n",
    "\n",
    "        return dataset\n",
    "        # return dataset.map(self.tokenize_function, batched=True, remove_columns=['cid', 'tid', 'text', 'fid', 'fact_text', 'is_head', 'linking', 'gold_reference', 'conv', '__index_level_0__'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transforming df Index(['dialog_id', 'head_old_label', 'head_gold_reference', 'head_fact_text',\n",
      "       'head_text', 'head_relation', 'tail_old_label', 'tail_gold_reference',\n",
      "       'tail_fact_text', 'tail_text', 'tail_relation', 'peacok_relation',\n",
      "       'gpt_output_head', 'gpt_output_tail', 'text', 'gold_reference',\n",
      "       'fact_text'],\n",
      "      dtype='object')\n",
      "transforming df Index(['dialog_id', 'head_old_label', 'head_gold_reference', 'head_fact_text',\n",
      "       'head_text', 'head_relation', 'tail_old_label', 'tail_gold_reference',\n",
      "       'tail_fact_text', 'tail_text', 'tail_relation', 'peacok_relation',\n",
      "       'gpt_output_head', 'gpt_output_tail', 'text', 'gold_reference',\n",
      "       'fact_text'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['dialog_id', 'dialog_dict', 'head_label', 'head_fact_text', 'gpt_output_head', 'tail_label', 'tail_fact_text', 'gpt_output_tail', 'peacok_relation', 'label'],\n",
       "        num_rows: 35821\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['dialog_id', 'dialog_dict', 'head_label', 'head_fact_text', 'gpt_output_head', 'tail_label', 'tail_fact_text', 'gpt_output_tail', 'peacok_relation', 'label'],\n",
       "        num_rows: 3981\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataset\n",
    "dataset_loader = DatasetLoader(TRAIN_DATA_PATH, VALID_DATA_PATH, DS_TYPE)\n",
    "dataset = dataset_loader.load()\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating parquet from Arrow format: 100%|██████████| 36/36 [00:00<00:00, 288.33ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:02<00:00,  2.75s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 4/4 [00:00<00:00, 374.01ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:00<00:00,  1.50it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/theirislin/synthetic_convai2_peacok_knowledge_linking/commit/86b687d7bc312cec15467b55f6236caf8fe742ca', commit_message='Upload dataset', commit_description='', oid='86b687d7bc312cec15467b55f6236caf8fe742ca', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_dataset_name = 'synthetic_convai2_peacok_knowledge_linking'\n",
    "dataset.push_to_hub(my_dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cpkl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
