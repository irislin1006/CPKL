{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iris/anaconda3/envs/cpkl/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset, DatasetDict, load_dataset\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from datasets import ClassLabel\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import nltk\n",
    "import evaluate\n",
    "import time\n",
    "\n",
    "\n",
    "# fix seeding for pytorch and huggingface\n",
    "import torch\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deberta NLU Head Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset config\n",
    "linking_data_path = \"./dimiss_items/data/model_gpt-3.5-turbo-0125\"\n",
    "TRAIN_DATA_PATH = f'{linking_data_path}/processed/gpt_label_full_train_df.json'\n",
    "VALID_DATA_PATH = f'{linking_data_path}/processed/gpt_label_full_valid_df.json'\n",
    "\n",
    "DS_TYPE = \"head\"\n",
    "USE_TAG = True\n",
    "\n",
    "LABEL_TO_ID = {\"entailment\": 0, \"not_entailment\": 1}\n",
    "ID_TO_LABEL = {0: \"entailment\", 1: \"not_entailment\"}\n",
    "\n",
    "COMFACT_LABEL_TO_ID = {True: 0, False: 1} # comFactDataLabelToId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def replace_phrases(sentence, person_a_tag):\n",
    "    sentence = sentence.lower()\n",
    "    # Pattern to find \"I am\" and replace with \"person a is\"\n",
    "    sentence = re.sub(r\"\\bi am\\b\", f\"{person_a_tag} is\", sentence, flags=re.IGNORECASE)\n",
    "    # Pattern to find \"I was\" and replace with \"person a was\"\n",
    "    sentence = re.sub(r\"\\bi was\\b\", f\"{person_a_tag} was\", sentence, flags=re.IGNORECASE)\n",
    "    sentence = re.sub(r\"\\bi\\b\", person_a_tag, sentence, flags=re.IGNORECASE)\n",
    "    sentence = re.sub(r\"\\bmy\\b\", f\"{person_a_tag}'s\", sentence, flags=re.IGNORECASE)\n",
    "    sentence = sentence.replace('person a', person_a_tag)\n",
    "    return sentence\n",
    "\n",
    "\n",
    "class DatasetLoader:\n",
    "    def __init__(self, train_data_path: str, valid_data_path: str, ds_type: str, sample_size: int = None):\n",
    "        self.train_data_path = train_data_path\n",
    "        self.valid_data_path = valid_data_path\n",
    "        self.sample_size = sample_size\n",
    "        self.pa_tag, self.pb_tag = 'Person A', 'Person B'\n",
    "        self.ds_type = ds_type\n",
    "\n",
    "    def get_conv_from_text(self, example):\n",
    "        center_utter = \"\"\n",
    "        post_utters, future_utters = [], []\n",
    "        for x in example['text']:\n",
    "            if x['type'] == 'ut':\n",
    "                center_utter = x['utter']\n",
    "            elif '-' in x['type']:\n",
    "                post_utters.append(x['utter'])\n",
    "            elif '+' in x['type']:\n",
    "                future_utters.append(x['utter'])\n",
    "\n",
    "        convs_list = '\\n'.join(post_utters + [center_utter] + future_utters)\n",
    "        return convs_list\n",
    "\n",
    "    def get_conv_with_tag_from_text(self, example):\n",
    "        def format_utter(utter, tag):\n",
    "            if utter.strip() == '':\n",
    "                return ''\n",
    "            return f\"{tag}: {utter}\"\n",
    "        center_utter = \"\"\n",
    "        post_utters, future_utters = [], []\n",
    "        for x in example['text']:\n",
    "            if x['type'] == 'ut':\n",
    "                center_utter = format_utter(x['utter'], self.pa_tag)\n",
    "            elif '-1' in x['type']:\n",
    "                post_utters.append(format_utter(x['utter'], self.pb_tag))\n",
    "            elif '-2' in x['type']:\n",
    "                post_utters.append(format_utter(x['utter'], self.pa_tag)) \n",
    "            elif '+1' in x['type']:\n",
    "                future_utters.append(format_utter(x['utter'], self.pb_tag)) \n",
    "            elif '+2' in x['type']:\n",
    "                future_utters.append(format_utter(x['utter'], self.pa_tag)) \n",
    "\n",
    "        convs_list = '\\n'.join(post_utters + [center_utter] + future_utters)\n",
    "        return convs_list #.lower()\n",
    "\n",
    "    def transform_df(self, df):\n",
    "        df['conv'] = df.apply(self.get_conv_from_text, axis=1) if not USE_TAG else df.apply(self.get_conv_with_tag_from_text, axis=1)\n",
    "        df['fact_text'] = df['fact_text'].apply(lambda x: x) if not USE_TAG else df['fact_text'].apply(lambda x: replace_phrases(x, self.pa_tag))\n",
    "        df['labels'] = df['gold_reference'].apply(lambda x: COMFACT_LABEL_TO_ID[x])\n",
    "        df['label_text'] = df['labels'].apply(lambda x: ID_TO_LABEL[x].lower())\n",
    "        return df\n",
    "\n",
    "    def create_pd_dataframe(self, data_path, sample_size=None):\n",
    "        df = pd.read_json(data_path)\n",
    "        # if self.ds_type == \"relation\":\n",
    "        #     df['peacok_relation'] = df['relation']\n",
    "        # if 'merged_head_tail' in data_path:\n",
    "        #     df = self.modify_merged_head_tail(df)\n",
    "        df = self.modify_merged_head_tail(df)\n",
    "        df = df.sample(sample_size) if sample_size else df\n",
    "        df = self.transform_df(df)\n",
    "        return df\n",
    "\n",
    "    def create_dataset(self, train_df, valid_df):\n",
    "        train_ds = Dataset.from_pandas(train_df)\n",
    "        valid_ds = Dataset.from_pandas(valid_df)\n",
    "\n",
    "        dataset = DatasetDict({\n",
    "            'train': train_ds,\n",
    "            'valid': valid_ds\n",
    "        })\n",
    "        return dataset\n",
    "    \n",
    "    # def get_relation(self, df):\n",
    "    #     return origonal_peacok_relation_df[origonal_peacok_relation_df['dialog_id'].isin(df['dialog_id'])]['peacok_relation']\n",
    "    \n",
    "    def modify_merged_head_tail(self, df):\n",
    "        if self.ds_type == \"head\":\n",
    "            df['gold_reference'] = df['gpt_tagged_head_gold_reference']\n",
    "            df['fact_text'] = df['gpt_tagged_head_fact_text']\n",
    "        elif self.ds_type == \"tail\":\n",
    "            df['gold_reference'] = df['gpt_tagged_tail_gold_reference']\n",
    "            df['fact_text'] = df['gpt_tagged_tail_fact_text']\n",
    "        elif self.ds_type == \"relation\":\n",
    "            # assert df['head_text'].equals(df['tail_text']), \"head and tail text should be the same\"\n",
    "            # df['text'] = df['tail_text']\n",
    "            df['gold_reference'] = df['gpt_tagged_head_gold_reference'] & df['gpt_tagged_tail_gold_reference']\n",
    "            df['fact_text'] = df.apply(lambda x: f\"{x['relation']} {x['gpt_tagged_head_fact_text']} and {x['gpt_tagged_tail_fact_text']}\", axis=1)\n",
    "            # df['fact_text'] = df.apply(lambda x: f\"{x['head_fact_text']} and {x['tail_fact_text']}; {x['peacok_relation']}\", axis=1)\n",
    "        else:\n",
    "            # assert df['head_text'].equals(df['tail_text']), \"head and tail text should be the same\"\n",
    "            # df['text'] = df['tail_text']\n",
    "            df['gold_reference'] = df['gpt_tagged_head_gold_reference'] & df['gpt_tagged_tail_gold_reference']\n",
    "            df['fact_text'] = df.apply(lambda x: f\"{x['gpt_tagged_head_fact_text']} and {x['gpt_tagged_tail_fact_text']}\", axis=1)\n",
    "        return df\n",
    "\n",
    "    def load(self):\n",
    "        train_df = self.create_pd_dataframe(self.train_data_path) # create_pd_dataframe(TRAIN_DATA_PATH, 5000)\n",
    "        valid_df = self.create_pd_dataframe(self.valid_data_path) # create_pd_dataframe(VALID_DATA_PATH, 500)\n",
    "        dataset = self.create_dataset(train_df, valid_df)\n",
    "        return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['dialog_id', 'relation', 'head', 'tail', 'text', 'gpt_tagged_head_old_label', 'gpt_tagged_head_gpt_output', 'gpt_tagged_head_fact_text', 'gpt_tagged_head_gold_reference', 'gpt_tagged_tail_gpt_output', 'gpt_tagged_tail_old_label', 'gpt_tagged_tail_action', 'gpt_tagged_tail_fact_text', 'gpt_tagged_tail_gold_reference', 'gold_reference', 'fact_text', 'conv', 'labels', 'label_text', '__index_level_0__'],\n",
       "        num_rows: 35821\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['dialog_id', 'relation', 'head', 'tail', 'text', 'gpt_tagged_head_old_label', 'gpt_tagged_head_gpt_output', 'gpt_tagged_head_fact_text', 'gpt_tagged_head_gold_reference', 'gpt_tagged_tail_gpt_output', 'gpt_tagged_tail_old_label', 'gpt_tagged_tail_action', 'gpt_tagged_tail_fact_text', 'gpt_tagged_tail_gold_reference', 'gold_reference', 'fact_text', 'conv', 'labels', 'label_text', '__index_level_0__'],\n",
       "        num_rows: 3981\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataset\n",
    "dataset_loader = DatasetLoader(TRAIN_DATA_PATH, VALID_DATA_PATH, DS_TYPE)\n",
    "dataset = dataset_loader.load()\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'additional_special_tokens': ['goal_plan_relationship',\n",
       "  'experience',\n",
       "  'routine_habit',\n",
       "  'goal_plan',\n",
       "  'characteristic_relationship',\n",
       "  'routine_habit_relationship',\n",
       "  'characteristic',\n",
       "  'experience_relationship']}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use train_ds and valid_ds to get all unique relations for specical tokenization\n",
    "relations_tokens = set(dataset['train']['relation'] + dataset['valid']['relation'])\n",
    "relations_special_tokens = {'additional_special_tokens': list(relations_tokens)}\n",
    "relations_special_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "head ds train len is 35821\n",
      "head Positive: 10533(0.2940453923676056)\n",
      "head Negative: 25288(0.7059546076323944)\n",
      "\n",
      "head ds valid len is 3981\n",
      "head Positive: 1149(0.2886209495101733)\n",
      "head Negative: 2832(0.7113790504898266)\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "counter = Counter([example['gold_reference'] for example in dataset['train']])\n",
    "valid_counter = Counter([example['gold_reference'] for example in dataset['valid']])\n",
    "\n",
    "print(f\"{DS_TYPE} ds train len is {len(dataset['train'])}\")\n",
    "print(f\"{DS_TYPE} Positive: {counter[True]}({counter[True]/len(dataset['train'])})\")\n",
    "print(f\"{DS_TYPE} Negative: {counter[False]}({counter[False]/len(dataset['train'])})\")\n",
    "print()\n",
    "print(f\"{DS_TYPE} ds valid len is {len(dataset['valid'])}\")\n",
    "print(f\"{DS_TYPE} Positive: {valid_counter[True]}({valid_counter[True]/len(dataset['valid'])})\")\n",
    "print(f\"{DS_TYPE} Negative: {valid_counter[False]}({valid_counter[False]/len(dataset['valid'])})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Person A: i don't have hair. i want to go to vegas. how are you? just to let you know i'm single.\n",
      "Person B: are you male or female? i can not wait to go back to school. do you use a wig? winter and fall is my favorite season\n",
      "Person A: i saw a wig on netflix. fall isn't that good. male, college? you do sleeping in? i do\n",
      "Person B: my sister loves me, and i love her. we are best friends. why not? does it get you down?\n",
      "Person A: it is just that in vegas fall causes weird people to come out. you saw right? i'm happy for you. love is so hard to come by. \n",
      "\n",
      "am always there for friends\n",
      "Person A is a loyal person\n",
      "None\n",
      "routine_habit_relationship\n",
      "Person A is a loyal person\n"
     ]
    }
   ],
   "source": [
    "print(dataset['train'][0]['conv'], '\\n')\n",
    "print(dataset['train'][0]['gpt_tagged_tail_fact_text'])\n",
    "print(dataset['train'][0]['gpt_tagged_head_fact_text'])\n",
    "print(dataset['train'][0]['gpt_tagged_tail_action'])\n",
    "print(dataset['train'][0]['relation'])\n",
    "print(dataset['train'][0]['fact_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "- Model Name: microsoft/deberta-v3-large\n",
      "- Model Size: large\n",
      "- Ds Type: head\n",
      "- Output Dir: ./dimiss_items/model/head/deberta-v3-large-1720879116/\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mirislin1006\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/c/Users/iris/Desktop/wsl_shared/CPKL/wandb/run-20240713_085837-pcf31tv1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/irislin1006/cpkl-head-microsoft-deberta-v3-large/runs/pcf31tv1' target=\"_blank\">deberta-v3-large-head</a></strong> to <a href='https://wandb.ai/irislin1006/cpkl-head-microsoft-deberta-v3-large' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/irislin1006/cpkl-head-microsoft-deberta-v3-large' target=\"_blank\">https://wandb.ai/irislin1006/cpkl-head-microsoft-deberta-v3-large</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/irislin1006/cpkl-head-microsoft-deberta-v3-large/runs/pcf31tv1' target=\"_blank\">https://wandb.ai/irislin1006/cpkl-head-microsoft-deberta-v3-large/runs/pcf31tv1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/irislin1006/cpkl-head-microsoft-deberta-v3-large/runs/pcf31tv1?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f72c15730a0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load model config\n",
    "IS_TRAIN_SAMPLED = False\n",
    "MODEL_SIZE = \"large\"\n",
    "MODEL_NAME = f\"microsoft/deberta-v3-{MODEL_SIZE}\"\n",
    "# MODEL_NAME = f\"MoritzLaurer/deberta-v3-large-zeroshot-v1.1-all-33\"\n",
    "OUTPUT_DIR = f\"./dimiss_items/model/{DS_TYPE}/deberta-v3-{MODEL_SIZE}-{str(int(time.time()))}/\"\n",
    "\n",
    "print(f\"\"\"\n",
    "- Model Name: {MODEL_NAME}\n",
    "- Model Size: {MODEL_SIZE}\n",
    "- Ds Type: {DS_TYPE}\n",
    "- Output Dir: {OUTPUT_DIR}\n",
    "\"\"\")\n",
    "\n",
    "import wandb\n",
    "wandb.init(project=f\"cpkl-{DS_TYPE}-{MODEL_NAME.replace('/', '-')}\", name=f\"deberta-v3-{MODEL_SIZE}-{DS_TYPE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_and_tokenizer(model_name, label2id, id2label):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=False, model_max_length=512)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_name, label2id=label2id, id2label=id2label)\n",
    "    \n",
    "    if DS_TYPE == \"relation\":\n",
    "        tokenizer.add_special_tokens(relations_special_tokens)\n",
    "        model.resize_token_embeddings(len(tokenizer))\n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iris/anaconda3/envs/cpkl/lib/python3.9/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=False, model_max_length=512)\n",
    "# model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, label2id=label2id, id2label=id2label)\n",
    "model, tokenizer = load_model_and_tokenizer(MODEL_NAME, LABEL_TO_ID, ID_TO_LABEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Dataset for trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 35821/35821 [00:11<00:00, 3245.71 examples/s]\n",
      "Map: 100%|██████████| 3981/3981 [00:01<00:00, 3172.79 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using head Dataset. Keys of tokenized dataset: ['labels', 'label_text', 'input_ids', 'token_type_ids', 'attention_mask']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def tokenize_function(examples):\n",
    "   return tokenizer(examples[\"conv\"], examples[\"fact_text\"], padding=True, truncation=True, max_length=512)\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize_function, batched=True, remove_columns=[\n",
    "   'dialog_id', \n",
    "   'text',\n",
    "   'relation',\n",
    "   'head',\n",
    "   'tail',\n",
    "   'gpt_tagged_head_old_label', \n",
    "   'gpt_tagged_head_gold_reference', \n",
    "   'gpt_tagged_head_fact_text', \n",
    "   'gpt_tagged_head_gpt_output', \n",
    "   'gpt_tagged_tail_old_label', \n",
    "   'gpt_tagged_tail_gold_reference', \n",
    "   'gpt_tagged_tail_fact_text', \n",
    "   'gpt_tagged_tail_gpt_output', \n",
    "   'gpt_tagged_tail_action', \n",
    "   'fact_text', \n",
    "   'gold_reference', \n",
    "   'conv',\n",
    "   '__index_level_0__'])\n",
    "print(f\"Using {DS_TYPE} Dataset. Keys of tokenized dataset: {list(tokenized_dataset['train'].features)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare trainer\n",
    "\n",
    "acc = evaluate.load(\"accuracy\")\n",
    "f1 = evaluate.load(\"f1\")\n",
    "precision = evaluate.load(\"precision\")\n",
    "recall = evaluate.load(\"recall\")\n",
    "roc_auc_score = evaluate.load(\"roc_auc\")\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    labels = eval_preds.label_ids\n",
    "    pred_logits = eval_preds.predictions\n",
    "    preds_max = np.argmax(pred_logits, axis=1)  # argmax on each row (axis=1) in the tensor\n",
    "    pred_probs = torch.softmax(torch.tensor(pred_logits), dim=1)[:, 0].numpy()\n",
    "      \n",
    "    print(\"Number of predictions: \", len(preds_max))\n",
    "    # compute f1, precision, recall, and accuracy \n",
    "    result = {}\n",
    "    result.update(acc.compute(predictions=preds_max, references=labels))\n",
    "    result.update(f1.compute(predictions=preds_max, references=labels, average='binary', pos_label=0))\n",
    "    result.update(precision.compute(predictions=preds_max, references=labels, average='binary', pos_label=0))\n",
    "    result.update(recall.compute(predictions=preds_max, references=labels, average='binary', pos_label=0))\n",
    "    result.update(roc_auc_score.compute(prediction_scores=pred_probs, references=1-labels))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trainer_args(output_dir):\n",
    "    if DS_TYPE == \"full\":\n",
    "        eval_steps=1500\n",
    "        save_steps=1500\n",
    "    elif DS_TYPE == \"head\":\n",
    "        eval_steps=3000\n",
    "        save_steps=3000\n",
    "    elif DS_TYPE == \"tail\":\n",
    "        # eval_steps=500\n",
    "        # save_steps=500\n",
    "        eval_steps=1500\n",
    "        save_steps=1500\n",
    "    elif DS_TYPE == \"relation\":\n",
    "        # eval_steps=500\n",
    "        # save_steps=500\n",
    "        eval_steps=1500\n",
    "        save_steps=1500\n",
    "    else:\n",
    "        raise ValueError(f\"'{DS_TYPE}' is invalid dataset type. Must be one of 'full', 'head', 'tail'\")\n",
    "    \n",
    "    return TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        per_device_train_batch_size=8,\n",
    "        per_device_eval_batch_size=8,\n",
    "        bf16 =False, # Overflows with bf16 \n",
    "        learning_rate=1e-6,\n",
    "        warmup_ratio=0.01,\n",
    "        weight_decay=0.01,\n",
    "        num_train_epochs=3,\n",
    "        # logging & evaluation strategies\n",
    "        logging_dir=f\"{output_dir}/logs\",\n",
    "        logging_strategy=\"steps\", \n",
    "        logging_steps=20,\n",
    "        evaluation_strategy=\"steps\",\n",
    "        eval_steps=eval_steps,\n",
    "        save_strategy=\"steps\",\n",
    "        save_steps=save_steps,\n",
    "        save_total_limit=5,\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"roc_auc\",\n",
    "        # push to hub parameters\n",
    "        report_to=\"wandb\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trainer(model, tokenized_dataset, output_dir):\n",
    "    training_args = get_trainer_args(output_dir)\n",
    "    trainer =Trainer(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_dataset[\"train\"],\n",
    "        eval_dataset=tokenized_dataset[\"valid\"],\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "    return trainer\n",
    "\n",
    "trainer = get_trainer(model, tokenized_dataset, OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13434' max='13434' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13434/13434 1:45:38, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Roc Auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.447300</td>\n",
       "      <td>0.427120</td>\n",
       "      <td>0.837980</td>\n",
       "      <td>0.705345</td>\n",
       "      <td>0.742308</td>\n",
       "      <td>0.671889</td>\n",
       "      <td>0.893957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.429700</td>\n",
       "      <td>0.403455</td>\n",
       "      <td>0.834464</td>\n",
       "      <td>0.729141</td>\n",
       "      <td>0.690810</td>\n",
       "      <td>0.771976</td>\n",
       "      <td>0.907435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.351300</td>\n",
       "      <td>0.402087</td>\n",
       "      <td>0.847526</td>\n",
       "      <td>0.738023</td>\n",
       "      <td>0.732021</td>\n",
       "      <td>0.744125</td>\n",
       "      <td>0.911173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.276000</td>\n",
       "      <td>0.415774</td>\n",
       "      <td>0.843507</td>\n",
       "      <td>0.737020</td>\n",
       "      <td>0.715574</td>\n",
       "      <td>0.759791</td>\n",
       "      <td>0.911340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of predictions:  3981\n",
      "Number of predictions:  3981\n",
      "Number of predictions:  3981\n",
      "Number of predictions:  3981\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=13434, training_loss=0.4042567425724011, metrics={'train_runtime': 6339.5753, 'train_samples_per_second': 16.951, 'train_steps_per_second': 2.119, 'total_flos': 5.091434603245229e+16, 'train_loss': 0.4042567425724011, 'epoch': 3.0})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of predictions:  3981\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot a roc curve with sk learn  and matplot lib\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_roc_curve(trainer, tokenized_dataset):\n",
    "    output = trainer.predict(tokenized_dataset[\"valid\"])\n",
    "    labels = 1 - output.label_ids\n",
    "    pred_logits = output.predictions\n",
    "    pred_probs = torch.softmax(torch.tensor(pred_logits), dim=1)[:, 0].numpy()\n",
    "    fpr, tpr, thresholds = roc_curve(labels, pred_probs, pos_label=1)\n",
    "    plt.plot(fpr, tpr, label=f\"ROC curve (area = {auc(fpr, tpr):.2f})\")\n",
    "    return pred_probs, thresholds\n",
    "\n",
    "pred_probs, thres = plot_roc_curve(trainer, tokenized_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.2\n",
      "{'accuracy': 0.832202964079377, 'f1': 0.7384494909945184, 'precision': 0.6711743772241993, 'recall': 0.8207136640557006, 'roc_auc': 0.9113399394216539}\n",
      "Threshold: 0.3\n",
      "{'accuracy': 0.8379804069329314, 'f1': 0.7398144413069786, 'precision': 0.6894736842105263, 'recall': 0.7980852915578764, 'roc_auc': 0.9113399394216539}\n",
      "Threshold: 0.4\n",
      "{'accuracy': 0.840241145440844, 'f1': 0.737190082644628, 'precision': 0.7018095987411487, 'recall': 0.7763272410791993, 'roc_auc': 0.9113399394216539}\n",
      "Threshold: 0.5\n",
      "{'accuracy': 0.84350665661894, 'f1': 0.7370198395947657, 'precision': 0.7155737704918033, 'recall': 0.7597911227154047, 'roc_auc': 0.9113399394216539}\n",
      "Threshold: 0.6\n",
      "{'accuracy': 0.8447626224566692, 'f1': 0.7343078245915736, 'precision': 0.7255734919286321, 'recall': 0.7432550043516101, 'roc_auc': 0.9113399394216539}\n",
      "Threshold: 0.7\n",
      "{'accuracy': 0.8460185882943984, 'f1': 0.7312582200789127, 'precision': 0.7367491166077739, 'recall': 0.7258485639686684, 'roc_auc': 0.9113399394216539}\n"
     ]
    }
   ],
   "source": [
    "# compute f1, precision, recall, and accuracy by given threshold\n",
    "def compute_metrics_with_threshold(pred_probs, thres, labels):\n",
    "    preds = (pred_probs > thres).astype(int)\n",
    "    result = {}\n",
    "    result.update(acc.compute(predictions=preds, references=labels))\n",
    "    result.update(f1.compute(predictions=preds, references=labels, average='binary', pos_label=1))\n",
    "    result.update(precision.compute(predictions=preds, references=labels, average='binary', pos_label=1))\n",
    "    result.update(recall.compute(predictions=preds, references=labels, average='binary', pos_label=1))\n",
    "    result.update(roc_auc_score.compute(prediction_scores=pred_probs, references=labels))\n",
    "    return result\n",
    "\n",
    "for t in [0.2, 0.3, 0.4, 0.5, 0.6, 0.7]:\n",
    "    print(f\"Threshold: {t}\")\n",
    "    print(compute_metrics_with_threshold(pred_probs, t, 1 - np.array(tokenized_dataset[\"valid\"][\"labels\"]).astype(int)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./dimiss_items/model/head/deberta-v3-large-1720879116/'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OUTPUT_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, tokenizer, output_dir):\n",
    "    model.save_pretrained(output_dir)\n",
    "    tokenizer.save_pretrained(output_dir)\n",
    "# OUTPUT_DIR = 'agents/dimiss_items/model/full/deberta-v3-large-1710086328/'\n",
    "save_model_path = OUTPUT_DIR + f\"deberta_v3_large_sample_{IS_TRAIN_SAMPLED}\"\n",
    "save_model(model, tokenizer, save_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cpkl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
